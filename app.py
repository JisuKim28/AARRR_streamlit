# import streamlit as st
# import pandas as pd
# import numpy as np
# import plotly.express as px
# from pathlib import Path
# import pandas as pd

# st.set_page_config(page_title="Google Merchandise Sale Prediction", layout="wide")

# # ì•± ì „ì²´ ë©”ì¸ íƒ€ì´í‹€

# st.markdown(
#     """
#     <h1 style="font-size:40px; font-weight:bold;">
#         <span style="color:#4285F4;">G</span>
#         <span style="color:#DB4437;">o</span>
#         <span style="color:#F4B400;">o</span>
#         <span style="color:#4285F4;">g</span>
#         <span style="color:#0F9D58;">l</span>
#         <span style="color:#DB4437;">e</span>
#         Merchandise Sale Prediction
#     </h1>
#     """,
#     unsafe_allow_html=True
# )

# # êµ¬ë¶„ì„ 
# st.markdown(
#     "<hr style='margin: 40px 0; border: 0; border-top: 1px solid #444;'>",
#     unsafe_allow_html=True
# )


# st.set_page_config(page_title="Overview", layout="wide")
# st.title("Overview")

# # CSV íŒŒì¼ ì§ì ‘ ì½ê¸°
# CSV_PATH = r"C:\Users\jisus\OneDrive\ë°”íƒ• í™”ë©´\Python\google_with_cluster3_aha.csv"
# df = pd.read_csv(CSV_PATH)

# # ---Overview---

# # ì„¸ì…˜ ID ìƒì„± (user + visitStartTime ì¡°í•©)
# df["sessionId"] = df["fullVisitorId"].astype(str) + "_" + df["visitStartTime"].astype(str)

# # --- KPI ê³„ì‚° ---
# total_sessions = df["sessionId"].nunique()
# unique_users = df["fullVisitorId"].nunique()

# # ì„¸ì…˜/ìœ ì € ë¹„ìœ¨
# sessions_per_user = total_sessions / unique_users if unique_users else 0

# # --- KPI ì¶œë ¥ ---
# c1, c2, c3 = st.columns(3)
# c1.metric("ì´ ì„¸ì…˜ ìˆ˜", f"{total_sessions:,}")
# c2.metric("ì´ ìœ ì € ìˆ˜", f"{unique_users:,}")
# c3.metric("ìœ ì €ë‹¹ í‰ê·  ë°©ë¬¸ íšŸìˆ˜", f"{sessions_per_user:.2f}")

# # --- í‰ê·  ì²´ë¥˜ ì‹œê°„ / í˜ì´ì§€ë·° ì‹œê°„ ---
# st.set_page_config(page_title="Overview", layout="wide")

# # ì„¸ì…˜ ID ìƒì„± (user + visitStartTime ì¡°í•©)
# df["sessionId"] = df["fullVisitorId"].astype(str) + "_" + df["visitStartTime"].astype(str)

# # --- KPI ê³„ì‚° ---
# # í‰ê·  ì²´ë¥˜ì‹œê°„ (ë¶„ ë‹¨ìœ„)
# avg_time_minutes = df["totalTimeOnSite"].mean() / 60

# # ì„¸ì…˜ë‹¹ í‰ê·  í˜ì´ì§€ë·°
# avg_pageviews = df["totalPageviews"].mean()

# # --- KPI ì¶œë ¥ ---
# c1, c2 = st.columns(2)
# c1.metric("í‰ê·  ì²´ë¥˜ì‹œê°„ (ë¶„)", f"{avg_time_minutes:.1f}")
# c2.metric("ì„¸ì…˜ë‹¹ í‰ê·  í˜ì´ì§€ë·°", f"{avg_pageviews:.2f}")

# # ----- ì‹ ê·œ/ì¬ë°©ë¬¸ ë¹„ìœ¨, ì¹´íŠ¸ì „í™˜ìœ¨ ---

# # ë°©ë¬¸ ìœ í˜• ë¼ë²¨ë§
# df["visit_type"] = np.where(pd.to_numeric(df["isFirstVisit"], errors="coerce") == 1, "ì‹ ê·œ", "ì¬ë°©ë¬¸")

# # addedToCart ë¶ˆë¦¬ì–¸ ë³€í™˜
# added_num = pd.to_numeric(df["addedToCart"], errors="coerce")
# added_str = df["addedToCart"].astype(str).str.lower()
# df["cart_flag"] = (added_num.fillna(0) > 0) | (added_str.isin(["1", "true", "t", "y", "yes"]))

# # âœ… summary ìƒì„±
# summary = (
#     df.groupby("visit_type")
#       .agg(
#           sessions=("fullVisitorId", "count"),
#           cart_sessions=("cart_flag", "sum")
#       )
#       .reset_index()
# )
# summary["cart_rate"] = summary["cart_sessions"] / summary["sessions"]

# # ë³´ê¸° ì¢‹ê²Œ í¬ë§·
# summary_view = summary.copy()
# summary_view["session_ratio(%)"] = (
#     summary_view["sessions"] / summary_view["sessions"].sum() * 100
# ).round(1).astype(str) + "%"
# summary_view["cart_rate(%)"] = (summary_view["cart_rate"] * 100).round(1).astype(str) + "%"

# st.subheader("ì‹ ê·œ/ì¬ë°©ë¬¸ íšŒì›ë³„ Cart ì „í™˜ìœ¨")

# # ì¢Œìš° ë°°ì¹˜
# left, right = st.columns([1, 1])

# with left:
#     st.dataframe(
#         summary_view[["visit_type", "session_ratio(%)", "cart_rate(%)"]],
#         use_container_width=True
#     )

# with right:
#     fig = px.bar(
#         summary,
#         x="visit_type",
#         y="cart_rate",
#         text=(summary["cart_rate"] * 100).round(1).astype(str) + "%",
#         labels={"visit_type": "ë°©ë¬¸ ìœ í˜•", "cart_rate": "Cart ì „í™˜ìœ¨"},
#         category_orders={"visit_type": ["ì‹ ê·œ", "ì¬ë°©ë¬¸"]},
#         color="visit_type",  # ìƒ‰ ê¸°ì¤€ ì»¬ëŸ¼
#         color_discrete_map={
#             "ì‹ ê·œ": "#4285F4",     # êµ¬ê¸€ íŒŒë€ìƒ‰
#             "ì¬ë°©ë¬¸": "#F4B400"   # êµ¬ê¸€ ë…¸ë€ìƒ‰
#         }
#     )
#     fig.update_yaxes(tickformat=".0%")
#     fig.update_traces(textposition="outside")
#     fig.update_layout(
#         bargap=0.7,   # ë§‰ëŒ€ ê°„ê²©
#         bargroupgap=0.1
#     )
#     st.plotly_chart(fig, use_container_width=True)

# # --- AHA ë‹¬ì„±ë¥  ---
# st.subheader("ì „ì²´ AHA ë‹¬ì„±ë¥ ")

# # AhaMomentë¥¼ ê²¬ê³ í•˜ê²Œ ë¶ˆë¦¬ì–¸ìœ¼ë¡œ ë³€í™˜
# s = df["AhaMoment"]
# if pd.api.types.is_bool_dtype(s):
#     aha = s.fillna(False)
# else:
#     num = pd.to_numeric(s, errors="coerce").fillna(0)
#     txt = s.astype(str).str.strip().str.lower()
#     aha = (num > 0) | (txt.isin(["true", "t", "y", "yes", "1"]))

# aha_rate = aha.mean()  # TRUE ë¹„ìœ¨

# # KPI
# st.metric("Aha ë‹¬ì„±ë¥ ", f"{aha_rate*100:.1f}%")

# # íŒŒì´ì°¨íŠ¸ (TRUE vs FALSE)
# pie_df = pd.DataFrame({
#     "Aha": ["TRUE", "FALSE"],
#     "count": [int(aha.sum()), int((~aha).sum())]
# })

# fig = px.pie(
#     pie_df,
#     names="Aha",
#     values="count",
#     hole=0.35,
#     color="Aha",
#     color_discrete_map={
#         "TRUE": "#F4B400",   # ë…¸ë‘
#         "FALSE": "#4285F4"   # íŒŒë‘
#     }
# )

# fig.update_traces(
#     textposition="inside",
#     texttemplate="%{label}: %{percent:.1%}"
# )

# # ğŸ‘‰ ì°¨íŠ¸ì™€ ì„¤ëª…ì„ ë‚˜ë€íˆ ë°°ì¹˜
# col1, col2 = st.columns([2, 1])

# with col1:
#     st.plotly_chart(fig, use_container_width=True)

# with col2:
#     st.markdown(
#         """
#         **AHA ëª¨ë¨¼íŠ¸ ì¸¡ì • ê¸°ì¤€**  
#         - ì²˜ìŒìœ¼ë¡œ ìƒí’ˆì„ ì¥ë°”êµ¬ë‹ˆì— ë‹´ì•˜ì„ ë•Œ  
#         - ì„¸ì…˜ ì‹œê°„(TimePerSession)ì´ ì¼ì • ê¸°ì¤€(ì˜ˆ: 3 ì´ìƒ)ì— ë„ë‹¬í–ˆì„ ë•Œ
#         """
#     )


# # --- í¼ë„ ë¶„ì„---
# import streamlit as st
# import pandas as pd
# import plotly.express as px

# st.subheader("í¼ë„ ë¶„ì„")

# step1 = (df["totalPageviews"] >= 1)
# step2 = (df["productPagesViewed"] >= 1)
# step3 = (pd.to_numeric(df["addedToCart"], errors="coerce").fillna(0) >= 1)

# n1 = int(step1.sum())
# n2 = int((step1 & step2).sum())
# n3 = int((step1 & step2 & step3).sum())

# conv12 = n2 / n1 if n1 else 0
# conv23 = n3 / n2 if n2 else 0
# conv_overall = n3 / n1 if n1 else 0

# k1, k2, k3 = st.columns(3)
# k1.metric("í˜ì´ì§€ë·°â†’ì œí’ˆìƒì„¸ ì „í™˜ìœ¨", f"{conv12*100:.1f}%")
# k2.metric("ì œí’ˆìƒì„¸â†’ì¹´íŠ¸ì¶”ê°€ ì „í™˜ìœ¨", f"{conv23*100:.1f}%")
# k3.metric("í˜ì´ì§€ë·°â†’ì¹´íŠ¸ì¶”ê°€ ì „í™˜ìœ¨", f"{conv_overall*100:.1f}%")

# # í¼ë„ ë°ì´í„°í”„ë ˆì„ (ê·¸ëŒ€ë¡œ)
# funnel_df = pd.DataFrame({
#     "Step": ["í˜ì´ì§€ë·° â‰¥1", "ì œí’ˆìƒì„¸ â‰¥1", "ì¹´íŠ¸ì¶”ê°€ â‰¥1"],
#     "Sessions": [n1, n2, n3]
# })

# # ì´ì „ ë‹¨ê³„ ëŒ€ë¹„ %
# pct_prev = [1.0, (n2 / n1) if n1 else 0, (n3 / n2) if n2 else 0]
# # ì²œë‹¨ìœ„ ì½¤ë§ˆ + í¼ì„¼íŠ¸
# funnel_df["Text"] = [f"{v:,.0f} ({p*100:.1f}%)" for v, p in zip(funnel_df["Sessions"], pct_prev)]

# # âœ… ê¸°ë³¸ value ë¼ë²¨(k ë‹¨ìœ„)ì„ ì—†ì• ê³ , ìš°ë¦¬ê°€ ë§Œë“  í…ìŠ¤íŠ¸ë§Œ í‘œì‹œ
# import plotly.express as px
# fig_funnel = px.funnel(funnel_df, x="Sessions", y="Step")

# fig_funnel.update_traces(
#     text=funnel_df["Text"],       # í‘œê¸°í•  í…ìŠ¤íŠ¸ ì§ì ‘ ì§€ì •
#     texttemplate="%{text}",       # ìš°ë¦¬ê°€ ë§Œë“  í…ìŠ¤íŠ¸ë§Œ í‘œì‹œ
#     textposition="inside",
#     textinfo="none",              # ê¸°ë³¸ textinfo ì œê±°
#     marker_color="#4285F4"        # ğŸ‘‰ í¼ë„ ìƒ‰ìƒ íŒŒë€ìƒ‰ìœ¼ë¡œ í†µì¼
# )

# st.plotly_chart(fig_funnel, use_container_width=True)

# st.markdown(
#     "<hr style='margin: 40px 0; border: 0; border-top: 1px solid #444;'>",
#     unsafe_allow_html=True
# )    

# # --- Cluster Summary Table ---
# # í¼ë„ ì°¨íŠ¸
# st.set_page_config(page_title="Cluster Summary", layout="wide")
# st.title("Cluster Summary Table")

# # í‘œ ë°ì´í„° ì •ì˜ + í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ì¶”ê°€
# data = {
#     "ê³ ê°êµ°": [
#         "íƒìƒ‰í˜• ê³ ê° (Explorers)", 
#         "ë¹„í™œì„± ê³ ê° (Visitors)", 
#         "ì¶©ì„±/í•µì‹¬ ê³ ê° (Core Buyers)"
#     ],
#     "ìœ ì € ìˆ˜": ["260,180", "305,542", "29,126"],
#     "Recency (ì¼)": [159.0, 164.4, 150.4],
#     "Frequency (ë°©ë¬¸ì¼ìˆ˜)": [1.21, 1.07, 1.75],
#     "Cart Rate": [0.01, 0.00, 0.77],
#     "Search Rate": [0.96, 0.01, 0.95],
#     "Time/Session (ì •ê·œí™”)": [1.19, 0.01, 5.32]
# }

# df_cluster = pd.DataFrame(data)

# # Streamlitì— í‘œì‹œ
# st.subheader("í´ëŸ¬ìŠ¤í„°ë³„ ìš”ì•½")
# st.dataframe(df_cluster, use_container_width=True)

# # --- í´ëŸ¬ìŠ¤í„°ë³„ ìœ ì € ë¹„ì¤‘ ---
# st.subheader("í´ëŸ¬ìŠ¤í„°ë³„ ìœ ì € ë¹„ì¤‘")

# # ë°ì´í„° ì •ì˜
# data = {
#     "Cluster": [0, 1, 2],
#     "í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼": [
#         "íƒìƒ‰í˜• ê³ ê° (Explorers)",
#         "ë¹„í™œì„± ê³ ê° (Visitors)",
#         "ì¶©ì„± ê³ ê° (Core Buyers)"
#     ],
#     "ìœ ì € ìˆ˜": [260180, 305542, 29126]  # ìˆ«ìë¡œ ë³€í™˜
# }

# df_cluster = pd.DataFrame(data)

# # Pie ì°¨íŠ¸
# # ë¼ë²¨ ì •ê·œí™” (ì•ë’¤ ê³µë°± ì œê±°)
# df_cluster["label"] = df_cluster["í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼"].str.strip()

# # ì›í•˜ëŠ” ìˆœì„œ (íƒìƒ‰=íŒŒë‘, ë¹„í™œì„±=ë…¸ë‘, ì¶©ì„±=ë¹¨ê°•)
# order = ["íƒìƒ‰í˜• ê³ ê° (Explorers)", "ë¹„í™œì„± ê³ ê° (Visitors)", "ì¶©ì„±/í•µì‹¬ ê³ ê° (Core Buyers)"]
# colors = ["#4285F4", "#F4B400", "#DB4437"]   # Google Blue, Yellow, Red

# fig = px.pie(
#     df_cluster,
#     names="label",
#     values="ìœ ì € ìˆ˜",
#     hole=0.3,
#     category_orders={"label": order},                 # ë¼ë²¨ ìˆœì„œ ê³ ì •
#     color="label",                                    # ìƒ‰ ê¸°ì¤€ ì»¬ëŸ¼
#     color_discrete_sequence=colors                    # ìˆœì„œì— ë§ì¶˜ ìƒ‰ ì ìš©
# )

# fig.update_traces(
#     textinfo="label+percent",
#     pull=[0.02, 0.02, 0.05],
#     rotation=90
# )

# fig.update_layout(
#     margin=dict(t=40, b=40, l=40, r=40),
#     legend=dict(orientation="h", y=-0.2, x=0.5, xanchor="center")
# )

# st.plotly_chart(fig, use_container_width=True)

# # êµ¬ë¶„ì„ 
# st.markdown(
#     "<hr style='margin: 40px 0; border: 0; border-top: 1px solid #444;'>",
#     unsafe_allow_html=True
# )

# # app.py â€” AARRR Dashboard (USER-level dedup with cluster population by unique users)
# # ìš”êµ¬ ì»¬ëŸ¼ ì˜ˆ: fullVisitorId, date, cluster, productPagesViewed, addedToCart,
# #               trafficMedium/trafficMed/trafficSource, deviceCategory, country,
# #               AhaMoment, (ì„ íƒ) TimePerSession_norm/TimePerSessionNorm

# import os, uuid
# from typing import Optional
# import numpy as np
# import pandas as pd
# import plotly.express as px
# import plotly.graph_objects as go
# import streamlit as st
# from pandas.api.types import is_datetime64tz_dtype

# # ---------------- Page/UI ----------------
# st.set_page_config(page_title="AARRR Dashboard", layout="wide")
# st.title("AARRR Dashboard â€” USER level")

# # -------- Colors & Cluster map --------
# GOOGLE_BLUE   = "#4285F4"    # single blue for funnel & bars
# GOOGLE_YELLOW = "#F4B400"    # cluster 1
# GOOGLE_RED    = "#DB4437"    # cluster 2
# GOOGLE_GREY   = "#9AA0A6"
# CLUSTER_COLORS = {"0": GOOGLE_BLUE, "1": GOOGLE_YELLOW, "2": GOOGLE_RED}
# DESIRED_ORDER = ["0", "1", "2"]

# def ukey(name): return f"{name}-{uuid.uuid4().hex[:8]}"

# # ---------------- Loader helpers ----------------
# NEEDED_BASE_COLS = {
#     "fullVisitorId","date","cluster",
#     "productPagesViewed","addedToCart",
#     "deviceCategory","country",
#     "trafficMedium","trafficMed","trafficSource",
#     "AhaMoment",
#     "TimePerSessionNorm","TimePerSession_norm","time_per_session",
#     "totalTimeOnSite","totalVisits",
#     # ğŸ‘‡ ë„ì‹œ ì»¬ëŸ¼ í›„ë³´ ì¶”ê°€ (ì—†ìœ¼ë©´ ë¡œë”ì—ì„œ ì˜ë ¤ ë‚˜ê°‘ë‹ˆë‹¤!)
#     "city", "City", "regionCity",
# }


# def _seek0(x):
#     try: x.seek(0)
#     except Exception: pass

# @st.cache_data(show_spinner=False, max_entries=1)
# def load_csv_smart(source, is_path: bool):
#     if not is_path: _seek0(source)
#     header = pd.read_csv(source, nrows=0, engine="python", on_bad_lines="skip")
#     cols = [c.strip() for c in header.columns]
#     usecols = [c for c in cols if c in NEEDED_BASE_COLS]

#     must = {"fullVisitorId","date","cluster","productPagesViewed","addedToCart","AhaMoment"}
#     missing = [c for c in must if c not in cols]
#     if missing:
#         raise RuntimeError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing}")

#     dtype_map = {"fullVisitorId":"string", "date":"string"}
#     try:
#         if not is_path: _seek0(source)
#         return pd.read_csv(source, engine="pyarrow", usecols=usecols, dtype=dtype_map)
#     except Exception:
#         pass
#     try:
#         if not is_path: _seek0(source)
#         return pd.read_csv(source, engine="python", usecols=usecols,
#                            dtype=dtype_map, on_bad_lines="skip")
#     except Exception:
#         pass

#     if not is_path: _seek0(source)
#     chunks = []
#     for chunk in pd.read_csv(source, engine="python", usecols=usecols,
#                              dtype=dtype_map, on_bad_lines="skip", chunksize=50_000):
#         chunks.append(chunk)
#     return pd.concat(chunks, ignore_index=True)

# def to_bool(s: pd.Series) -> pd.Series:
#     if s.dtype == bool: return s
#     try: return (pd.to_numeric(s, errors="coerce").fillna(0) > 0)
#     except Exception:
#         ss = s.astype(str).str.lower().str.strip()
#         return ss.isin({"1","true","t","y","yes"})

# def ensure_dt(s: pd.Series) -> pd.Series:
#     out = pd.to_datetime(s, errors="coerce")
#     if is_datetime64tz_dtype(out):
#         try: out = out.dt.tz_convert("UTC").dt.tz_localize(None)
#         except AttributeError: out = out.dt.tz_localize(None)
#     return out

# # ---------------- Data load ----------------
# st.sidebar.header("ë°ì´í„°")
# default_path = "./google_with_cluster3_aha.csv"
# up   = st.sidebar.file_uploader("CSV ì—…ë¡œë“œ(ì„ íƒ)", type=["csv"])
# path = st.sidebar.text_input("ê²½ë¡œ(ì„ íƒ)", value=default_path)

# if up is not None:
#     df = load_csv_smart(up, is_path=False)
#     st.success("ì—…ë¡œë“œí•œ íŒŒì¼ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
# else:
#     if not os.path.exists(path):
#         st.error(f"ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {path}"); st.stop()
#     df = load_csv_smart(path, is_path=True)
#     st.info(f"ê¸°ë³¸ ê²½ë¡œì—ì„œ ë¡œë“œ: {path}")

# if df.empty:
#     st.error("ë¹ˆ ë°ì´í„°ì…ë‹ˆë‹¤."); st.stop()

# # ---------------- Preprocess ----------------
# user_col     = "fullVisitorId"
# date_col     = "date"
# cluster_col  = "cluster"
# detail_col   = "productPagesViewed"
# cart_col     = "addedToCart"
# device_col   = "deviceCategory"
# country_col  = "country"

# # channel column
# if "trafficMedium" in df.columns:
#     medium_col = "trafficMedium"
# elif "trafficMed" in df.columns:
#     medium_col = "trafficMed"
# elif "trafficSource" in df.columns:
#     medium_col = "trafficSource"
# else:
#     st.error("ì±„ë„ ì°¨ì›ì„ ìœ„í•œ trafficMedium/trafficMed/trafficSource ì¤‘ í•˜ë‚˜ê°€ í•„ìš”í•©ë‹ˆë‹¤."); st.stop()

# # session time column (optional)
# sess_time_col = "TimePerSession_norm" if "TimePerSession_norm" in df.columns \
#     else ("TimePerSessionNorm" if "TimePerSessionNorm" in df.columns else None)

# # type cleaning
# session_col = "_session_surrogate"
# df = df.copy()
# df[user_col] = df[user_col].astype("string").fillna("")
# cnum = pd.to_numeric(df[cluster_col], errors="coerce").astype("Int64")
# df = df[cnum.isin([0,1,2])].copy()
# df[cluster_col] = cnum.astype("Int64").astype(str)

# df[date_col] = ensure_dt(df[date_col])
# df = df[df[date_col].notna()]
# df[detail_col] = pd.to_numeric(df[detail_col], errors="coerce").fillna(0)
# df[cart_col]   = to_bool(df[cart_col])
# df["AhaMoment"] = to_bool(df["AhaMoment"])

# # session surrogate (30m bucket if time present, else date)
# if df[date_col].dt.time.astype(str).nunique() > 1:
#     bucket = df[date_col].dt.floor("30min").astype(str)
# else:
#     bucket = df[date_col].dt.strftime("%Y-%m-%d")
# df[session_col] = (df[user_col].astype(str) + "|" + bucket)

# # ---------------- Date filter ----------------
# st.sidebar.header("ê¸°ê°„")
# min_d, max_d = df[date_col].min().date(), df[date_col].max().date()
# start = st.sidebar.date_input("ì‹œì‘ì¼", value=min_d)
# end   = st.sidebar.date_input("ì¢…ë£Œì¼", value=max_d)

# start_dt = pd.Timestamp(start)
# end_dt   = pd.Timestamp(end) + pd.Timedelta(days=1) - pd.Timedelta(nanoseconds=1)
# dfp = df[(df[date_col] >= start_dt) & (df[date_col] <= end_dt)].copy()
# if dfp.empty:
#     st.warning("ì„ íƒ êµ¬ê°„ ë°ì´í„° ì—†ìŒ"); st.stop()

# # ---------------- Representative cluster (mode) for user snapshot ----------------
# def rep_mode(s: pd.Series) -> Optional[str]:
#     m = pd.to_numeric(s, errors="coerce"); m = m[m.notna()]
#     if m.empty: return None
#     return str(int(m.mode().iat[0]))

# # ìµœì‹  ìŠ¤ëƒ…ìƒ·(ìœ ì € ìµœì‹  í–‰) â€” Activation/ë¶„ëª¨ ìš©
# df_user_last = (
#     dfp.sort_values([user_col, date_col])
#        .drop_duplicates(subset=[user_col], keep="last")
#        [[user_col, cluster_col, "AhaMoment", cart_col]]
#        .copy()
# )
# df_user_last[cluster_col] = df_user_last[cluster_col].astype(str)
# df_user_last["AhaMoment"] = to_bool(df_user_last["AhaMoment"])
# df_user_last["cart_bool"] = to_bool(df_user_last[cart_col])

# # ê¸°ê°„ ì „ì²´ í–‰ë™(any) + ëŒ€í‘œ í´ëŸ¬ìŠ¤í„°(ìµœë¹ˆê°’) â€” í¼ë„/ë¦¬í…ì…˜ ìš©
# rep_cluster_mode = (dfp.groupby(user_col)[cluster_col].apply(rep_mode)
#                        .reset_index(name=cluster_col))
# user_any = (dfp.groupby(user_col)
#               .agg(detail_any=(detail_col, lambda s: int((pd.to_numeric(s, errors="coerce").fillna(0) > 0).any())),
#                    cart_any=(cart_col, "any"))
#               .reset_index())
# uf = user_any.merge(rep_cluster_mode, on=user_col, how="left")
# uf["home"] = 1

# # # =========================================================
# # # 1) Overview
# # # =========================================================
# # st.header("1. Overview (USER ê¸°ì¤€)")

# # # session-level funnel (reference)
# # sess_agg = dfp.groupby(session_col).agg(
# #     detail_any=(detail_col, lambda s: (s>0).any()),
# #     cart_any=(cart_col, "any"),
# # )
# # home_cnt = int(len(sess_agg))
# # detail_cnt = int(sess_agg["detail_any"].sum())
# # cart_cnt   = int(sess_agg["cart_any"].sum())

# # m1,m2,m3,m4 = st.columns(4)
# # m1.metric("ì´ ì„¸ì…˜", f"{home_cnt:,}")
# # m2.metric("ì´ ìœ ì €", f"{dfp[user_col].nunique():,}")
# # # Aha ê²½í—˜ë¥ (ìœ ì €, ìµœì‹  ìŠ¤ëƒ…ìƒ·)
# # aha_overall_rate = (df_user_last["AhaMoment"].mean() if len(df_user_last) else np.nan)
# # m3.metric("Aha ê²½í—˜ë¥ (ìœ ì €, ìµœì‹  ìŠ¤ëƒ…ìƒ·)", f"{aha_overall_rate:.1%}" if pd.notna(aha_overall_rate) else "NA")
# # m4.metric("ì„¸ì…˜ í¼ë„ ì „í™˜ìœ¨", f"{(cart_cnt/home_cnt):.1%}" if home_cnt else "NA")

# # st.plotly_chart(go.Figure(go.Funnel(
# #     y=["Home(ì„¸ì…˜)","Detail","Cart"],
# #     x=[home_cnt, detail_cnt, cart_cnt],
# #     textposition="inside", textinfo="value+percent previous"
# # )), use_container_width=True, key=ukey("overview-funnel"))

# # if sess_time_col is not None:
# #     st.plotly_chart(px.histogram(
# #         dfp.groupby(session_col)[sess_time_col].mean().reset_index(),
# #         x=sess_time_col, nbins=40, title="ì„¸ì…˜ í‰ê·  ì²´ë¥˜ì‹œê°„(ì •ê·œí™”) ë¶„í¬",
# #         color_discrete_sequence=[GOOGLE_BLUE]
# #     ), use_container_width=True, key=ukey("overview-time"))

# # with st.expander("ì›ë³¸ ì§‘ê³„ ì ê²€ (í–‰/ìœ ì €/ì„¸ì…˜ surrogate)"):
# #     st.write({
# #         "rows_after_filter": len(dfp),
# #         "unique_users": int(dfp[user_col].nunique()),
# #         "sessions_surrogate": int(dfp[session_col].nunique())
# #     })

# # =========================================================
# # 2) Activation â€” ë¶„ëª¨=í´ëŸ¬ìŠ¤í„° ì¸ì›(ìœ ì € ìŠ¤ëƒ…ìƒ·)
# # =========================================================
# st.header("1. Activation (ë¶„ëª¨=í´ëŸ¬ìŠ¤í„° ì¸ì›, ìœ ì € ìµœì‹  ìŠ¤ëƒ…ìƒ·)")

# # ë¶„ëª¨(í´ëŸ¬ìŠ¤í„° ì¸ì›)
# cluster_pop = (df_user_last.groupby(cluster_col)[user_col]
#                .nunique().rename("cluster_users").reset_index())
# cluster_pop[cluster_col] = pd.Categorical(cluster_pop[cluster_col], categories=DESIRED_ORDER, ordered=True)
# cluster_pop = cluster_pop.sort_values(cluster_col)

# # Aha true
# aha_true = (df_user_last.groupby(cluster_col)["AhaMoment"]
#             .sum().rename("aha_true").reset_index())

# aha_rate_den_cluster = (cluster_pop.merge(aha_true, on=cluster_col, how="left")
#                         .fillna({"aha_true":0})
#                         .assign(aha_rate=lambda t: t["aha_true"] / t["cluster_users"].replace(0, np.nan))
#                         [[cluster_col,"cluster_users","aha_true","aha_rate"]])
# aha_rate_den_cluster[cluster_col] = pd.Categorical(
#     aha_rate_den_cluster[cluster_col], categories=DESIRED_ORDER, ordered=True)
# aha_rate_den_cluster = aha_rate_den_cluster.sort_values(cluster_col)

# # Ahaâ†’Cart (ì „ì²´ ëŒ€ë¹„)
# aha_cart_true = ((df_user_last["AhaMoment"] & df_user_last["cart_bool"])
#                  .groupby(df_user_last[cluster_col]).sum()
#                  .rename("aha_cart_true").reset_index())

# aha_cart_overall_den_cluster = (cluster_pop.merge(aha_cart_true, on=cluster_col, how="left")
#                                 .fillna({"aha_cart_true":0})
#                                 .assign(aha_cart_overall=lambda t: t["aha_cart_true"] / t["cluster_users"].replace(0, np.nan))
#                                 [[cluster_col,"cluster_users","aha_cart_true","aha_cart_overall"]])
# aha_cart_overall_den_cluster[cluster_col] = pd.Categorical(
#     aha_cart_overall_den_cluster[cluster_col], categories=DESIRED_ORDER, ordered=True)
# aha_cart_overall_den_cluster = aha_cart_overall_den_cluster.sort_values(cluster_col)

# # Aha ë‹¬ì„±ë¥  ì°¨íŠ¸
# fig_aha = px.bar(
#     aha_rate_den_cluster, y=cluster_col, x="aha_rate", orientation="h",
#     title="í´ëŸ¬ìŠ¤í„°ë³„ Aha ë‹¬ì„±ë¥  (ë¶„ëª¨=í´ëŸ¬ìŠ¤í„° ì¸ì›)",
#     color=cluster_col, color_discrete_map=CLUSTER_COLORS,
#     labels={"aha_rate":"Aha ë‹¬ì„±ë¥ ", cluster_col:"Cluster"}
# )
# fig_aha.update_yaxes(categoryorder="array", categoryarray=DESIRED_ORDER)
# fig_aha.update_traces(texttemplate="%{x:.1%}", textposition="outside", showlegend=False)
# fig_aha.update_layout(xaxis_tickformat=".1%")
# st.plotly_chart(fig_aha, use_container_width=True, key=ukey("act-aha"))

# # Ahaâ†’Cart (ì „ì²´ ëŒ€ë¹„) ì°¨íŠ¸
# fig_aha_cart = px.bar(
#     aha_cart_overall_den_cluster, y=cluster_col, x="aha_cart_overall", orientation="h",
#     title="í´ëŸ¬ìŠ¤í„°ë³„ Aha â†’ Cart (ë¶„ëª¨=í´ëŸ¬ìŠ¤í„° ì¸ì›)",
#     color=cluster_col, color_discrete_map=CLUSTER_COLORS,
#     labels={"aha_cart_overall":"Ahaâ†’Cart (ì „ì²´ ëŒ€ë¹„)", cluster_col:"Cluster"}
# )
# fig_aha_cart.update_yaxes(categoryorder="array", categoryarray=DESIRED_ORDER)
# fig_aha_cart.update_traces(texttemplate="%{x:.1%}", textposition="outside", showlegend=False)
# fig_aha_cart.update_layout(xaxis_tickformat=".1%")
# st.plotly_chart(fig_aha_cart, use_container_width=True, key=ukey("act-aha-cart"))

# # ìˆ«ì í‘œ
# st.dataframe(
#     aha_rate_den_cluster.merge(
#         aha_cart_overall_den_cluster[[cluster_col,"aha_cart_true","aha_cart_overall"]],
#         on=cluster_col, how="left"
#     ).rename(columns={
#         "cluster_users":"í´ëŸ¬ìŠ¤í„° ì¸ì›",
#         "aha_true":"Aha True ìˆ˜",
#         "aha_rate":"Aha ë‹¬ì„±ë¥ ",
#         "aha_cart_true":"Ahaâˆ©Cart True ìˆ˜",
#         "aha_cart_overall":"Ahaâ†’Cart (ì „ì²´ ëŒ€ë¹„)"
#     })[[cluster_col,"í´ëŸ¬ìŠ¤í„° ì¸ì›","Aha True ìˆ˜","Aha ë‹¬ì„±ë¥ ","Ahaâˆ©Cart True ìˆ˜","Ahaâ†’Cart (ì „ì²´ ëŒ€ë¹„)"]],
#     use_container_width=True
# )

# # =========================================================
# # 3) Funnel (USER ê¸°ì¤€ / í™ˆ ê¸°ì¤€, ê²Œì´íŠ¸ì‹) â€” í´ëŸ¬ìŠ¤í„°ë³„ë§Œ í‘œì‹œ
# # =========================================================
# st.subheader("í¼ë„ ì „í™˜ìœ¨")

# # ì „ì²´ íƒ­ ì œê±° â†’ Cluster 0, 1, 2ë§Œ
# tabs = st.tabs(["Cluster 0", "Cluster 1", "Cluster 2"])
# tab_keys = ["0", "1", "2"]

# def draw_home_based_funnel(uv: pd.DataFrame, title: str, key_sfx: str):
#     h = int(len(uv))
#     d = int((uv["detail_any"] == 1).sum())
#     k = int(((uv["detail_any"] == 1) & (uv["cart_any"] == 1)).sum())

#     pct_detail = (d / h) if h else np.nan
#     pct_cart   = (k / h) if h else np.nan

#     seg_text = [
#         f"{h:,}\n100%",
#         f"{d:,}\n{pct_detail:.1%} (Homeâ†’Detail)",
#         f"{k:,}\n{pct_cart:.1%} (Homeâ†’Cart via Detail)",
#     ]

#     fig = go.Figure(go.Funnel(
#         y=["Home","Detail","Cart(Detail ê²½ìœ )"],
#         x=[h, d, k],
#         text=seg_text,
#         textposition="inside",
#         textinfo="text",  # Plotly ê¸°ë³¸ percent ì œê±°
#         marker={"color": [GOOGLE_BLUE, GOOGLE_BLUE, GOOGLE_BLUE]},
#         hovertemplate="%{y}: %{x:,}<extra></extra>",
#     ))
#     fig.update_layout(title=title)
#     st.plotly_chart(fig, use_container_width=True, key=ukey(f"funnel-{key_sfx}"))

#     st.dataframe(pd.DataFrame([{
#         "home_users": h,
#         "detail_users": d,
#         "cart_users": k,
#         "Homeâ†’Detail(%)": round((pct_detail * 100), 1) if h else np.nan,
#         "Homeâ†’Cart(Detail ê²½ìœ )(%)": round((pct_cart * 100), 1) if h else np.nan,
#         "Detailâ†’Cart(%)": round(((k / d) * 100), 1) if d else np.nan,
#     }]), use_container_width=True)

# # í´ëŸ¬ìŠ¤í„°ë³„ íƒ­ë§Œ
# for t, key in zip(tabs, tab_keys):
#     with t:
#         uv = uf[uf[cluster_col] == key].copy()
#         draw_home_based_funnel(uv, f"Funnel (Cluster {key})", key)

# # =========================================================
# # 4) Acquisition (USER ê¸°ì¤€) â€” íƒ­ í´ë¦­ ë°©ì‹ (ì±„ë„/ë””ë°”ì´ìŠ¤/êµ­ê°€/ë„ì‹œ)
# # =========================================================
# st.header("2. Acquisition (USER ê¸°ì¤€)")

# # ê³µí†µ ì˜µì…˜
# cA, cB = st.columns([1,1])
# with cA:
#     min_share = st.slider("ìµœì†Œ ìœ ì… ë¹„ì¤‘ ì œì™¸", 0.0, 0.2, 0.01, 0.005, key=ukey("acq-minshare"))
# with cB:
#     top_n = st.number_input("TOP N", min_value=3, max_value=30, value=10, step=1, key=ukey("acq-topn"))

# # ----- í´ë¦° ìœ í‹¸: ì¼ë°˜ ì°¨ì›(ë””ë°”ì´ìŠ¤/êµ­ê°€ ë“±)
# def _clean_series_exclude_noise(s: pd.Series) -> pd.Series:
#     ss = s.astype(str).str.strip()
#     bad = {"", "nan", "(none)", "none", "(not set)", "not set", "unavailable"}
#     return ss.where(~ss.str.lower().isin(bad), other=np.nan)

# # ----- í´ë¦° ìœ í‹¸: ì±„ë„ì€ (none)ì„ ìœ ì§€ (ë¹ˆê°’/nan/(not set)/unavailableë§Œ ì œê±°)
# def _clean_channel_keep_none(s: pd.Series) -> pd.Series:
#     ss = s.astype(str).str.strip()
#     bad = {"", "nan", "(not set)", "not set", "unavailable"}
#     return ss.where(~ss.str.lower().isin(bad), other=np.nan)

# # ----- ê³µí†µ ë Œë” í•¨ìˆ˜(ë¹„-ì±„ë„ìš©): ë””ë°”ì´ìŠ¤/êµ­ê°€ ë“±ì€ ê¸°ì¡´ ê·œì¹™ ìœ ì§€
# def render_acquisition_for_dim(dfp_src: pd.DataFrame, dim_col: str, title_prefix: str):
#     dfp_acq = dfp_src.copy()

#     # ìœ ì € ê¸°ì¤€ ìœ ì… ë¹„ì¤‘: ìœ ì €ì˜ 'ìµœê·¼' í•´ë‹¹ ì°¨ì›ì„ ëŒ€í‘œê°’ìœ¼ë¡œ ì‚¬ìš©
#     rep_dim = (
#         dfp_acq[[user_col, dim_col, date_col]]
#         .sort_values([user_col, date_col])
#         .drop_duplicates(user_col, keep="last")[[user_col, dim_col]]
#         .copy()
#     )
#     rep_dim[dim_col] = _clean_series_exclude_noise(rep_dim[dim_col])

#     acq = (
#         rep_dim.dropna(subset=[dim_col])[dim_col]
#         .value_counts(normalize=True)
#         .rename_axis(dim_col)
#         .reset_index(name="share")
#         .sort_values("share", ascending=False)
#     )
#     acq = acq[acq["share"] >= float(min_share)].head(int(top_n))
#     order = acq[dim_col].tolist()

#     fig_share = px.bar(
#         acq, x=dim_col, y="share",
#         title=f"{title_prefix} ìƒìœ„ {len(acq)} ìœ ì… ë¹„ì¤‘ (USER)",
#         color_discrete_sequence=[GOOGLE_BLUE]
#     )
#     fig_share.update_traces(texttemplate="%{y:.1%}", textposition="outside", showlegend=False)
#     fig_share.update_layout(yaxis_tickformat=".1%")
#     fig_share.update_xaxes(categoryorder="array", categoryarray=order)
#     st.plotly_chart(fig_share, use_container_width=True, key=ukey(f"acq-share-{dim_col}"))

#     # ë™ì¼ ì¹´í…Œê³ ë¦¬ ì „í™˜ìœ¨ (ì„¸ì…˜â†’Cart)
#     sess_cart = (
#         dfp_acq.dropna(subset=[dim_col])
#               .groupby([dim_col, session_col])[cart_col].any()
#               .reset_index()
#     )
#     conv = (
#         sess_cart.groupby(dim_col)[cart_col].mean()
#                  .reset_index(name="conversion")
#     )
#     conv = conv[conv[dim_col].isin(order)]
#     conv[dim_col] = pd.Categorical(conv[dim_col], categories=order, ordered=True)
#     conv = conv.sort_values(dim_col)

#     fig_conv = px.bar(
#         conv, x=dim_col, y="conversion",
#         title=f"{title_prefix}ë³„ ì „í™˜ìœ¨ (ì„¸ì…˜â†’ì¥ë°”êµ¬ë‹ˆ, %)",
#         color_discrete_sequence=[GOOGLE_BLUE]
#     )
#     fig_conv.update_traces(texttemplate="%{y:.1%}", textposition="outside", showlegend=False)
#     fig_conv.update_layout(yaxis_tickformat=".1%")
#     fig_conv.update_xaxes(categoryorder="array", categoryarray=order)
#     st.plotly_chart(fig_conv, use_container_width=True, key=ukey(f"acq-conv-{dim_col}"))

# # íƒ­ êµ¬ì„±: ì±„ë„ / ë””ë°”ì´ìŠ¤ / êµ­ê°€ / ë„ì‹œ
# tab_channel, tab_device, tab_country, tab_city = st.tabs(["ì±„ë„", "ë””ë°”ì´ìŠ¤", "êµ­ê°€", "ë„ì‹œ"])

# # ---------- ì±„ë„ íƒ­: (none) í¬í•¨í•˜ì—¬ ìœ ì… ë¹„ì¤‘/ì „í™˜ìœ¨ ë Œë” ----------
# with tab_channel:
#     st.subheader("ì±„ë„ (trafficMedium) â€” (none í¬í•¨)")

#     # USER ìµœì‹  ìŠ¤ëƒ…ìƒ· ê¸°ì¤€ ëŒ€í‘œ ì±„ë„
#     rep_medium = (
#         dfp[[user_col, medium_col, date_col]]
#         .sort_values([user_col, date_col])
#         .drop_duplicates(user_col, keep="last")[[user_col, medium_col]]
#         .copy()
#     )
#     rep_medium[medium_col] = _clean_channel_keep_none(rep_medium[medium_col])

#     channel_share = (
#         rep_medium.dropna(subset=[medium_col])[medium_col]
#         .value_counts(normalize=True)
#         .rename_axis(medium_col)
#         .reset_index(name="share")
#         .sort_values("share", ascending=False)
#     )
#     channel_share = channel_share[channel_share["share"] >= float(min_share)]
#     channel_share = channel_share.head(int(top_n))
#     order_channels = channel_share[medium_col].tolist()

#     fig_ch_share = px.bar(
#         channel_share, x=medium_col, y="share",
#         title=f"ì±„ë„ë³„ ìœ ì… ë¹„ì¤‘ (USER) â€” Top {len(channel_share)}",
#         color_discrete_sequence=[GOOGLE_BLUE]
#     )
#     fig_ch_share.update_traces(texttemplate="%{y:.1%}", textposition="outside", showlegend=False)
#     fig_ch_share.update_layout(yaxis_tickformat=".1%")
#     fig_ch_share.update_xaxes(categoryorder="array", categoryarray=order_channels)
#     st.plotly_chart(fig_ch_share, use_container_width=True, key=ukey("acq-channel-share"))

#     # ì „í™˜ìœ¨(ì„¸ì…˜â†’Cart): (none) í¬í•¨í•´ì„œ ê³„ì‚°
#     df_conv = dfp.copy()
#     df_conv[medium_col] = _clean_channel_keep_none(df_conv[medium_col])
#     df_conv = df_conv.dropna(subset=[medium_col])

#     sess_cart = (
#         df_conv.groupby([medium_col, session_col])[cart_col].any()
#                .reset_index()
#     )
#     conv = (
#         sess_cart.groupby(medium_col)[cart_col]
#                  .mean().reset_index(name="conversion")
#     )
#     # ìœ ì… Top ì±„ë„ë§Œ í‘œì‹œ + ê°™ì€ ìˆœì„œ
#     conv = conv[conv[medium_col].isin(order_channels)]
#     conv[medium_col] = pd.Categorical(conv[medium_col], categories=order_channels, ordered=True)
#     conv = conv.sort_values(medium_col)

#     fig_ch_conv = px.bar(
#         conv, x=medium_col, y="conversion",
#         title="ì±„ë„ë³„ ì „í™˜ìœ¨ (ì„¸ì…˜â†’ì¥ë°”êµ¬ë‹ˆ, %)",
#         color_discrete_sequence=[GOOGLE_BLUE]
#     )
#     fig_ch_conv.update_traces(texttemplate="%{y:.1%}", textposition="outside", showlegend=False)
#     fig_ch_conv.update_layout(yaxis_tickformat=".1%")
#     fig_ch_conv.update_xaxes(categoryorder="array", categoryarray=order_channels)
#     st.plotly_chart(fig_ch_conv, use_container_width=True, key=ukey("acq-channel-conv"))

# with tab_device:
#     render_acquisition_for_dim(dfp, device_col, "ë””ë°”ì´ìŠ¤")

# with tab_country:
#     render_acquisition_for_dim(dfp, country_col, "êµ­ê°€")


# # --------------------------- ë„ì‹œ íƒ­ ---------------------------
# with tab_city:
#     # (none / not set / unavailable / demo placeholder) ê°’ë“¤ ì œê±°
#     def _clean_city(s: pd.Series) -> pd.Series:
#         ss = s.astype(str).str.strip()
#         bad = {
#             "", "nan",
#             "(none)", "none",
#             "(not set)", "not set",
#             "unavailable",
#             "not available in demo dataset",  # ğŸ‘ˆ ì¶”ê°€ë¡œ ì œì™¸
#         }
#         return ss.where(~ss.str.lower().isin(bad), other=np.nan)

#     # dfpì— ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ë„ì‹œ ì»¬ëŸ¼ ìë™ ì„ íƒ
#     possible_city_cols = ["city", "City", "regionCity"]
#     city_col = next((c for c in possible_city_cols if c in dfp.columns), None)

#     # ---- ë„ì‹œë³„ ìœ ì… TopN & ì „í™˜ìœ¨ (ìƒë‹¨) ----
#     if city_col is not None:
#         # ìœ ì… ë¹„ì¤‘ TopN (USER ìµœì‹  ìŠ¤ëƒ…ìƒ·)
#         rep_city = (
#             dfp[[user_col, city_col, date_col]]
#               .sort_values([user_col, date_col])
#               .drop_duplicates(user_col, keep="last")[[user_col, city_col]]
#               .copy()
#         )
#         rep_city[city_col] = _clean_city(rep_city[city_col])

#         top_n_cities = int(top_n) if "top_n" in globals() else 10
#         city_share = (
#             rep_city.dropna(subset=[city_col])[city_col]
#                     .value_counts(normalize=True)
#                     .rename_axis(city_col).reset_index(name="share")
#                     .sort_values("share", ascending=False)
#                     .head(top_n_cities)
#         )

#         if not city_share.empty:
#             order_cities = city_share[city_col].tolist()

#             fig_city_share = px.bar(
#                 city_share, x=city_col, y="share",
#                 title="ë„ì‹œë³„ ìœ ì… ë¹„ì¤‘ Top N (USER)",
#                 color_discrete_sequence=[GOOGLE_BLUE]
#             )
#             fig_city_share.update_traces(texttemplate="%{y:.1%}", textposition="outside", showlegend=False)
#             fig_city_share.update_layout(yaxis_tickformat=".1%")
#             fig_city_share.update_xaxes(categoryorder="array", categoryarray=order_cities)
#             st.plotly_chart(fig_city_share, use_container_width=True, key=ukey("city-share"))

#             # ë„ì‹œë³„ ì „í™˜ìœ¨(ì„¸ì…˜â†’Cart) â€” ìœ ì… ìƒìœ„ ë„ì‹œì— í•œì •
#             df_city_conv = dfp.copy()
#             df_city_conv[city_col] = _clean_city(df_city_conv[city_col])
#             df_city_conv = df_city_conv.dropna(subset=[city_col])

#             sess_city = (
#                 df_city_conv.groupby([city_col, session_col])[cart_col]
#                             .any().reset_index()
#             )
#             conv_city = (
#                 sess_city.groupby(city_col)[cart_col]
#                          .mean().reset_index(name="conversion")
#             )
#             conv_city = conv_city[conv_city[city_col].isin(order_cities)]
#             conv_city[city_col] = pd.Categorical(conv_city[city_col],
#                                                  categories=order_cities, ordered=True)
#             conv_city = conv_city.sort_values(city_col)

#             fig_city_conv = px.bar(
#                 conv_city, x=city_col, y="conversion",
#                 title="ë„ì‹œë³„ ì „í™˜ìœ¨ (ì„¸ì…˜â†’ì¥ë°”êµ¬ë‹ˆ, %)",
#                 color_discrete_sequence=[GOOGLE_BLUE]
#             )
#             fig_city_conv.update_traces(texttemplate="%{y:.1%}", textposition="outside", showlegend=False)
#             fig_city_conv.update_layout(yaxis_tickformat=".1%")
#             fig_city_conv.update_xaxes(categoryorder="array", categoryarray=order_cities)
#             st.plotly_chart(fig_city_conv, use_container_width=True, key=ukey("city-conv"))
#         else:
#             st.info("í‘œì‹œí•  ë„ì‹œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
#     else:
#         st.warning("ë„ì‹œ ì»¬ëŸ¼(city/City/regionCity)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë¡œë” í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ í™•ì¸)")

#     # ---- ê³ ì°©ë„: íƒ­ í´ë¦­(ì¼/ì£¼) â€” ë„ì‹œ ìœ ë¬´ì™€ ë¬´ê´€í•˜ê²Œ í•­ìƒ í‘œì‹œ ----
#     d0 = dfp[[date_col, user_col]].drop_duplicates().copy()
#     d0[date_col] = pd.to_datetime(d0[date_col], errors="coerce")
#     d0 = d0[d0[date_col].notna()]
#     d0["date"]  = d0[date_col].dt.normalize()
#     d0["week"]  = d0[date_col].dt.to_period("W").dt.start_time
#     d0["month"] = d0[date_col].dt.to_period("M").dt.start_time

#     tab_day, tab_week = st.tabs(["ì¼ë³„ ê³ ì°©ë„ (WAU/DAU)", "ì£¼ë³„ ê³ ì°©ë„ (MAU/WAU)"])

#     with tab_day:
#         if d0.empty:
#             st.info("ê³ ì°©ë„ ê³„ì‚°ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
#         else:
#             daily = d0.groupby("date")[user_col].nunique().rename("DAU").reset_index()
#             # ë‚ ì§œë³„ 7ì¼ rolling windowë¡œ WAU ê³„ì‚°
#             dates_sorted = daily["date"].sort_values()
#             wau = []
#             for d in dates_sorted:
#                 win = d0[(d0["date"] >= (d - pd.Timedelta(days=6))) & (d0["date"] <= d)]
#                 wau.append({"date": d, "WAU": win[user_col].nunique()})
#             stick_daily = daily.merge(pd.DataFrame(wau), on="date", how="left")
#             stick_daily["WAU/DAU"] = (stick_daily["WAU"] / stick_daily["DAU"]).replace([np.inf, -np.inf], np.nan)

#             fig_stick_daily = px.line(
#                 stick_daily, x="date", y="WAU/DAU",
#                 title="ê³ ì°©ë„ (WAU/DAU, ì¼ë³„)"
#             )
#             st.plotly_chart(fig_stick_daily, use_container_width=True, key=ukey("stick-wau-dau-citytab"))

#     with tab_week:
#         if d0.empty:
#             st.info("ê³ ì°©ë„ ê³„ì‚°ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
#         else:
#             weekly  = d0.groupby("week")[user_col].nunique().rename("WAU").reset_index()
#             monthly = d0.groupby("month")[user_col].nunique().rename("MAU").reset_index()
#             weekly["month"] = pd.to_datetime(weekly["week"]).dt.to_period("M").dt.start_time
#             wk = weekly.merge(monthly, on="month", how="left")
#             wk["MAU/WAU"] = (wk["MAU"] / wk["WAU"]).replace([np.inf, -np.inf], np.nan)

#             fig_stick_weekly = px.line(
#                 wk, x="week", y="MAU/WAU",
#                 title="ê³ ì°©ë„ (MAU/WAU, ì£¼ë³„)"
#             )
#             st.plotly_chart(fig_stick_weekly, use_container_width=True, key=ukey("stick-mau-wau-citytab"))






# # =========================================================
# # 5) Retention â€” íƒ­(í´ë¦­) ë°©ì‹ + í•œ ë²ˆì— 30/90ì¼ ê³„ì‚°
# # =========================================================
# st.header("3. Retention")

# # ì½”í˜¸íŠ¸ ì¤€ë¹„ (ìœ ì €-ë‚ ì§œ ì¤‘ë³µ ì œê±° í›„ ì •ë ¬)
# cohort = (
#     dfp[[user_col, cluster_col, date_col]]
#       .drop_duplicates()
#       .sort_values([user_col, date_col])
# )

# # ëŒ€í‘œ í´ëŸ¬ìŠ¤í„°(ê¸°ê°„ ë‚´ ìµœë¹ˆê°’) â€” ê¸°ì¡´ì— rep_clusterê°€ ìˆìœ¼ë©´ ì¬ì‚¬ìš©
# def _rep_mode(s: pd.Series):
#     m = pd.to_numeric(s, errors="coerce")
#     m = m[m.notna()]
#     return str(int(m.mode().iat[0])) if not m.mode().empty else None

# rep_cluster_mode = (
#     cohort.groupby(user_col)[cluster_col]
#           .apply(_rep_mode)
#           .reset_index(name=cluster_col)
# )

# # ì²« ë°©ë¬¸ì¼ ê³„ì‚°
# first_visit = (
#     cohort.groupby(user_col, as_index=False)[date_col]
#           .min()
#           .rename(columns={date_col: "first_visit"})
# )

# # ìœ ì €-ë°©ë¬¸ ë ˆë²¨ì— ì²« ë°©ë¬¸ì¼ ë¶™ì—¬ì„œ, 30/90ì¼ ì¬ë°©ë¬¸ ì—¬ë¶€ë¥¼ í•œ ë²ˆì— ê³„ì‚°
# cohort2 = cohort.merge(first_visit, on=user_col, how="left")
# def _ret_flag(days: int) -> pd.Series:
#     limit = cohort2["first_visit"] + pd.to_timedelta(days, "D")
#     flag = (cohort2[date_col] > cohort2["first_visit"]) & (cohort2[date_col] <= limit)
#     return cohort2.assign(flag=flag).groupby(user_col)["flag"].any().rename(f"ret_{days}")

# ret30 = _ret_flag(30)
# ret90 = _ret_flag(90)

# # ìœ ì € ë‹¨ìœ„ í…Œì´ë¸”(ìµœì´ˆ ë°©ë¬¸ + 30/90ì¼ ì¬ë°©ë¬¸ + ì½”í˜¸íŠ¸ì›” + ëŒ€í‘œí´ëŸ¬ìŠ¤í„°)
# ur = (
#     first_visit
#       .merge(ret30.reset_index(), on=user_col, how="left")
#       .merge(ret90.reset_index(), on=user_col, how="left")
#       .merge(rep_cluster_mode, on=user_col, how="left")
# )
# ur["cohort_month"] = ur["first_visit"].dt.to_period("M").dt.start_time

# def render_retention_heatmap(ret_col: str, window_label: str, key_suffix: str):
#     pivot = (
#         ur.groupby(["cohort_month", cluster_col])[ret_col]
#           .mean().reset_index()
#           .pivot(index="cohort_month", columns=cluster_col, values=ret_col)
#     )
#     pivot.columns = pivot.columns.astype(str)
#     col_order = [c for c in DESIRED_ORDER if c in pivot.columns]
#     if col_order:
#         pivot = pivot[col_order]

#     z = pivot.values
#     x = list(pivot.columns)
#     y = [pd.to_datetime(d).strftime("%Y-%m") for d in pivot.index]
#     text = np.where(np.isnan(z), "", (z*100).round(1).astype(str) + "%")

#     fig = go.Figure(data=go.Heatmap(
#         z=z, x=x, y=y, colorscale="Blues",
#         hovertemplate="Cohort %{y}<br>Cluster %{x}<br>Retention %{z:.1%}<extra></extra>"
#     ))
#     fig.update_layout(title=f"í´ëŸ¬ìŠ¤í„°ë³„ ì½”í˜¸íŠ¸ ìœ ì§€ìœ¨ Heatmap ({window_label}) â€” (ì—´=Cluster, í–‰=Cohort Month)")
#     fig.add_trace(go.Scatter(
#         x=np.repeat(x, len(y)), y=np.tile(y, len(x)),
#         mode="text", text=text.flatten(), hoverinfo="skip", showlegend=False
#     ))
#     st.plotly_chart(fig, use_container_width=True, key=ukey(f"ret-heatmap-{key_suffix}"))

# # ğŸ‘‡ íƒ­(í´ë¦­) ë°©ì‹: ë¡œë”© ì—†ì´ ì „í™˜
# tab30, tab90 = st.tabs(["30ì¼", "90ì¼"])
# with tab30:
#     render_retention_heatmap("ret_30", "30ì¼", "30")
# with tab90:
#     render_retention_heatmap("ret_90", "90ì¼", "90")


# # Cart usage (user-level)
# cart_usage = (uf.groupby(cluster_col)["cart_any"]
#               .mean().reset_index(name="cart_usage_rate"))
# cart_usage[cluster_col] = pd.Categorical(cart_usage[cluster_col].astype(str),
#                                          categories=DESIRED_ORDER, ordered=True)
# cart_usage = cart_usage.sort_values(cluster_col)

# fig_cu = px.bar(
#     cart_usage, x=cluster_col, y="cart_usage_rate",
#     title="í´ëŸ¬ìŠ¤í„°ë³„ ì¥ë°”êµ¬ë‹ˆ ì´ìš©ë¥  (ìœ ì € ê¸°ì¤€)",
#     color=cluster_col, color_discrete_map=CLUSTER_COLORS,
#     labels={"cart_usage_rate":"ì¥ë°”êµ¬ë‹ˆ ì´ìš©ë¥ ", cluster_col:"Cluster"}
# )
# fig_cu.update_traces(texttemplate="%{y:.1%}", textposition="outside", showlegend=False)
# fig_cu.update_layout(yaxis_tickformat=".1%")
# st.plotly_chart(fig_cu, use_container_width=True, key=ukey("ret-cart-usage"))


# st.caption("â€» ë¶„ëª¨=í´ëŸ¬ìŠ¤í„° ì¸ì›ì€ ìœ ì € ìµœì‹  ìŠ¤ëƒ…ìƒ·(ì¤‘ë³µ ì œê±°)ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤. í¼ë„/ë¦¬í…ì…˜ì€ ê¸°ê°„ ì „ì²´ any ê¸°ì¤€. ì±„ë„ì€ trafficMediumâ†’trafficMedâ†’trafficSource ìš°ì„  ì‚¬ìš©.")

# =========================================================
# 1) ë°ì´í„° ë¡œë”: ì—…ë¡œë“œ CSV/ZIP ë˜ëŠ” ë¦¬í¬ì§€í† ë¦¬ ë‚´ CSV/ZIP (ë©”ëª¨ë¦¬ ì ˆì•½í˜•)
# =========================================================
from zipfile import ZipFile
from pathlib import Path
import pandas as pd
import numpy as np
import streamlit as st

REPO_CSV = Path(__file__).parent / "google_with_cluster3_aha.csv"
REPO_ZIP = Path(__file__).parent / "google_with_cluster3_aha.zip"

st.sidebar.header("ë°ì´í„°")
uploaded = st.sidebar.file_uploader("CSV ë˜ëŠ” ZIP ì—…ë¡œë“œ(ì„ íƒ)", type=["csv", "zip"])

# ---- ë©”ëª¨ë¦¬ ì ˆì•½ ì„¤ì • ----
st.sidebar.subheader("ë©”ëª¨ë¦¬ ì ˆì•½ ì„¤ì •")
lite_mode = st.sidebar.checkbox("ë©”ëª¨ë¦¬ ì ˆì•½ ëª¨ë“œ(ìƒ˜í”Œë§)", value=True)
n_rows = st.sidebar.number_input("ì½ì„ ìµœëŒ€ í–‰ ìˆ˜ (ìƒ˜í”Œë§)", min_value=10_000, max_value=5_000_000,
                                 step=10_000, value=500_000)
downcast_obj_to_cat = st.sidebar.checkbox("ë¬¸ìì—´ì„ categoryë¡œ ë³€í™˜", value=True)

# ì•±ì—ì„œ ì‹¤ì œë¡œ ì‚¬ìš©í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì§€ì •
USECOLS = [
    "fullVisitorId","date","cluster",
    "visitStartTime","totalTimeOnSite","totalPageviews",
    "productPagesViewed","addedToCart","AhaMoment",
    "isFirstVisit","deviceCategory","country",
    "trafficMedium","trafficMed","trafficSource",
    "city","City","regionCity"
]

# ë” ì‘ì€ dtypeìœ¼ë¡œ ì§€ì •
DTYPES = {
    "fullVisitorId": "string",
    "cluster": "Int8",
    "visitStartTime": "Int64",
    "totalTimeOnSite": "float32",
    "totalPageviews": "float32",
    "productPagesViewed": "float32",
    "addedToCart": "float32",   # ë‚˜ì¤‘ì— bool ë¡œì§ ì ìš©
    "isFirstVisit": "Int8",
}

def _read_csv(file_like_or_path):
    """í•„ìš” ì»¬ëŸ¼ë§Œ, ì‘ì€ dtypeìœ¼ë¡œ, (ì˜µì…˜) ìƒ˜í”Œë§í•´ì„œ ì½ê¸°"""
    # pyarrow ê°€ ìˆìœ¼ë©´ ì†ë„/ë©”ëª¨ë¦¬ ìœ ë¦¬, ì—†ìœ¼ë©´ pandas ê¸°ë³¸ ì—”ì§„
    engine = "pyarrow"
    try:
        import pyarrow  # noqa: F401
    except Exception:
        engine = "python"

    return pd.read_csv(
        file_like_or_path,
        usecols=lambda c: c in USECOLS,
        dtype=DTYPES,
        parse_dates=["date"],
        infer_datetime_format=True,
        dayfirst=False,
        nrows=(int(n_rows) if lite_mode else None),
        engine=engine,
        on_bad_lines="skip",
        low_memory=False,
    )

def _read_from_zip(src):
    with ZipFile(src) as zf:
        names = [n for n in zf.namelist() if n.lower().endswith(".csv")]
        if not names:
            raise RuntimeError("ZIP ì•ˆì—ì„œ CSV íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        with zf.open(names[0]) as f:
            return _read_csv(f)

# ---- ìš°ì„ ìˆœìœ„: ì—…ë¡œë“œ > ë¦¬í¬ì§€í† ë¦¬ CSV > ë¦¬í¬ì§€í† ë¦¬ ZIP ----
if uploaded is not None:
    if uploaded.name.lower().endswith(".csv"):
        df = _read_csv(uploaded)
        st.success("ì—…ë¡œë“œí•œ CSVë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
    else:
        df = _read_from_zip(uploaded)
        st.success("ì—…ë¡œë“œí•œ ZIPì—ì„œ CSVë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
elif REPO_CSV.exists():
    df = _read_csv(REPO_CSV)
    st.info(f"ë¦¬í¬ì§€í† ë¦¬ CSVì—ì„œ ë¡œë“œ: {REPO_CSV.name}")
elif REPO_ZIP.exists():
    df = _read_from_zip(REPO_ZIP)
    st.info(f"ë¦¬í¬ì§€í† ë¦¬ ZIPì—ì„œ ë¡œë“œ: {REPO_ZIP.name}")
else:
    st.error("ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CSV/ZIPì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ë¦¬í¬ì§€í† ë¦¬ì— ì¶”ê°€í•˜ì„¸ìš”.")
    st.stop()

# ---- ì¶”ê°€ ë‹¤ìš´ìºìŠ¤íŠ¸/ì •ë¦¬ ----
# ìˆ«ì downcast
for c in df.select_dtypes(include=["float64"]).columns:
    df[c] = pd.to_numeric(df[c], errors="coerce", downcast="float")
for c in df.select_dtypes(include=["int64"]).columns:
    df[c] = pd.to_numeric(df[c], errors="coerce", downcast="integer")

# ë„ì‹œ ì»¬ëŸ¼ í‘œì¤€í™” (city í•˜ë‚˜ë¡œ)
if "City" in df.columns and "city" not in df.columns:
    df = df.rename(columns={"City": "city"})
if "regionCity" in df.columns and "city" not in df.columns:
    df = df.rename(columns={"regionCity": "city"})

# ë¬¸ìì—´ â†’ category (ë©”ëª¨ë¦¬ ì ˆê°)
if downcast_obj_to_cat:
    obj_cols = df.select_dtypes(include=["object", "string"]).columns.tolist()
    for c in obj_cols:
        if c not in {"date", "fullVisitorId"}:
            df[c] = df[c].astype("category")

if df.empty:
    st.error("ë¹ˆ ë°ì´í„°ì…ë‹ˆë‹¤."); st.stop()


# =========================================================
# 2) ê³µí†µ ìœ í‹¸/ì „ì²˜ë¦¬ (í˜• ë³€í™˜ ë“±)
# =========================================================
def to_bool(s: pd.Series) -> pd.Series:
    if s.dtype == bool:
        return s.fillna(False)
    try:
        return (pd.to_numeric(s, errors="coerce").fillna(0) > 0)
    except Exception:
        ss = s.astype(str).str.lower().str.strip()
        return ss.isin({"1", "true", "t", "y", "yes"})

def ensure_dt(s: pd.Series) -> pd.Series:
    out = pd.to_datetime(s, errors="coerce")
    if is_datetime64tz_dtype(out):
        try:
            out = out.dt.tz_convert("UTC").dt.tz_localize(None)
        except AttributeError:
            out = out.dt.tz_localize(None)
    return out

# ì»¬ëŸ¼ ì´ë¦„ ì¤€ë¹„
user_col     = "fullVisitorId"
date_col     = "date"
cluster_col  = "cluster"
detail_col   = "productPagesViewed"
cart_col     = "addedToCart"
device_col   = "deviceCategory"
country_col  = "country"

# ì±„ë„ ì»¬ëŸ¼ ìë™ ì„ íƒ
if "trafficMedium" in df.columns:
    medium_col = "trafficMedium"
elif "trafficMed" in df.columns:
    medium_col = "trafficMed"
elif "trafficSource" in df.columns:
    medium_col = "trafficSource"
else:
    medium_col = None

# íƒ€ì… ì •ë¦¬ (ê°€ëŠ¥í•œ í•œ ê²¬ê³ í•˜ê²Œ)
if user_col in df.columns:
    df[user_col] = df[user_col].astype("string").fillna("")
if date_col in df.columns:
    df[date_col] = ensure_dt(df[date_col])
if detail_col in df.columns:
    df[detail_col] = pd.to_numeric(df[detail_col], errors="coerce").fillna(0)
if cart_col in df.columns:
    df[cart_col] = to_bool(df[cart_col])
if "AhaMoment" in df.columns:
    df["AhaMoment"] = to_bool(df["AhaMoment"])
if cluster_col in df.columns:
    cnum = pd.to_numeric(df[cluster_col], errors="coerce").astype("Int64")
    df = df[cnum.isin([0, 1, 2])].copy()
    df[cluster_col] = cnum.astype("Int64").astype(str)

# date í•„í„°ë¥¼ ìœ„í•œ ê²€ì¦
if date_col not in df.columns or df[date_col].notna().sum() == 0:
    st.error("`date` ì»¬ëŸ¼ì´ ì—†ê±°ë‚˜ í˜•ì‹ì´ ì˜ëª»ë˜ì–´ ìˆìŠµë‹ˆë‹¤."); st.stop()
df = df[df[date_col].notna()].copy()

# ì„¸ì…˜ surrogate (ìˆìœ¼ë©´ 30ë¶„ ë²„í‚·, ì—†ìœ¼ë©´ ë‚ ì§œ ë‹¨ìœ„)
session_col = "_session_surrogate"
if df[date_col].dt.time.astype(str).nunique() > 1:
    bucket = df[date_col].dt.floor("30min").astype(str)
else:
    bucket = df[date_col].dt.strftime("%Y-%m-%d")
if user_col in df.columns:
    df[session_col] = (df[user_col].astype(str) + "|" + bucket)
else:
    df[session_col] = bucket  # fallback


# =========================================================
# 3) í—¤ë”/íƒ€ì´í‹€
# =========================================================
st.markdown(
    """
    <h1 style="font-size:40px; font-weight:bold;">
        <span style="color:#4285F4;">G</span>
        <span style="color:#DB4437;">o</span>
        <span style="color:#F4B400;">o</span>
        <span style="color:#4285F4;">g</span>
        <span style="color:#0F9D58;">l</span>
        <span style="color:#DB4437;">e</span>
        Merchandise Sale Prediction
    </h1>
    """,
    unsafe_allow_html=True
)
st.markdown("<hr style='margin: 40px 0; border: 0; border-top: 1px solid #444;'>", unsafe_allow_html=True)
st.title("Overview")


# =========================================================
# 4) Overview (ì„¸ì…˜/ìœ ì €/KPI)
#    â€» ê¸°ì¡´ì˜ 'ìœˆë„ìš° ê²½ë¡œ'ë¡œ CSV ì½ë˜ ë¶€ë¶„ì„ ëª¨ë‘ ì œê±°
# =========================================================

# visitStartTimeì´ ìˆìœ¼ë©´ ì„¸ì…˜ ID ìƒì„±ì— í™œìš© (ì—†ì–´ë„ ë™ì‘)
if {"fullVisitorId", "visitStartTime"}.issubset(df.columns):
    df["sessionId"] = df["fullVisitorId"].astype(str) + "_" + df["visitStartTime"].astype(str)
else:
    df["sessionId"] = df.get(session_col, pd.Series(range(len(df)))).astype(str)

total_sessions = df["sessionId"].nunique()
unique_users = df[user_col].nunique() if user_col in df.columns else np.nan
sessions_per_user = (total_sessions / unique_users) if unique_users else 0

c1, c2, c3 = st.columns(3)
c1.metric("ì´ ì„¸ì…˜ ìˆ˜", f"{total_sessions:,}")
c2.metric("ì´ ìœ ì € ìˆ˜", f"{unique_users:,}" if pd.notna(unique_users) else "NA")
c3.metric("ìœ ì €ë‹¹ í‰ê·  ë°©ë¬¸ íšŸìˆ˜", f"{sessions_per_user:.2f}" if unique_users else "NA")

# í‰ê·  ì²´ë¥˜ì‹œê°„ / í˜ì´ì§€ë·°
avg_time_minutes = (pd.to_numeric(df.get("totalTimeOnSite"), errors="coerce").mean() or 0) / 60
avg_pageviews = pd.to_numeric(df.get("totalPageviews"), errors="coerce").mean() or 0
c1, c2 = st.columns(2)
c1.metric("í‰ê·  ì²´ë¥˜ì‹œê°„ (ë¶„)", f"{avg_time_minutes:.1f}")
c2.metric("ì„¸ì…˜ë‹¹ í‰ê·  í˜ì´ì§€ë·°", f"{avg_pageviews:.2f}")

# ì‹ ê·œ/ì¬ë°©ë¬¸ ë¹„ìœ¨ + ì¹´íŠ¸ì „í™˜ìœ¨
if "isFirstVisit" in df.columns and cart_col in df.columns:
    df["visit_type"] = np.where(pd.to_numeric(df["isFirstVisit"], errors="coerce") == 1, "ì‹ ê·œ", "ì¬ë°©ë¬¸")
    added_num = pd.to_numeric(df["addedToCart"], errors="coerce")
    added_str = df["addedToCart"].astype(str).str.lower()
    df["cart_flag"] = (added_num.fillna(0) > 0) | (added_str.isin(["1", "true", "t", "y", "yes"]))

    summary = (
        df.groupby("visit_type")
          .agg(sessions=("fullVisitorId", "count"), cart_sessions=("cart_flag", "sum"))
          .reset_index()
    )
    summary["cart_rate"] = summary["cart_sessions"] / summary["sessions"]

    st.subheader("ì‹ ê·œ/ì¬ë°©ë¬¸ íšŒì›ë³„ Cart ì „í™˜ìœ¨")
    left, right = st.columns([1, 1])
    with left:
        summary_view = summary.copy()
        summary_view["session_ratio(%)"] = (
            summary_view["sessions"] / summary_view["sessions"].sum() * 100
        ).round(1).astype(str) + "%"
        summary_view["cart_rate(%)"] = (summary_view["cart_rate"] * 100).round(1).astype(str) + "%"
        st.dataframe(summary_view[["visit_type", "session_ratio(%)", "cart_rate(%)"]], use_container_width=True)
    with right:
        fig = px.bar(
            summary,
            x="visit_type",
            y="cart_rate",
            text=(summary["cart_rate"] * 100).round(1).astype(str) + "%",
            labels={"visit_type": "ë°©ë¬¸ ìœ í˜•", "cart_rate": "Cart ì „í™˜ìœ¨"},
            category_orders={"visit_type": ["ì‹ ê·œ", "ì¬ë°©ë¬¸"]},
            color="visit_type",
            color_discrete_map={"ì‹ ê·œ": "#4285F4", "ì¬ë°©ë¬¸": "#F4B400"},
        )
        fig.update_yaxes(tickformat=".0%")
        fig.update_traces(textposition="outside")
        fig.update_layout(bargap=0.7, bargroupgap=0.1)
        st.plotly_chart(fig, use_container_width=True)

# AHA ë‹¬ì„±ë¥ 
if "AhaMoment" in df.columns:
    s = df["AhaMoment"]
    aha = s if pd.api.types.is_bool_dtype(s) else (
        (pd.to_numeric(s, errors="coerce").fillna(0) > 0) |
        (s.astype(str).str.strip().str.lower().isin(["true", "t", "y", "yes", "1"]))
    )
    aha_rate = aha.mean()
    st.subheader("ì „ì²´ AHA ë‹¬ì„±ë¥ ")
    st.metric("Aha ë‹¬ì„±ë¥ ", f"{aha_rate*100:.1f}%")
    pie_df = pd.DataFrame({"Aha": ["TRUE", "FALSE"], "count": [int(aha.sum()), int((~aha).sum())]})
    fig = px.pie(
        pie_df, names="Aha", values="count", hole=0.35, color="Aha",
        color_discrete_map={"TRUE": "#F4B400", "FALSE": "#4285F4"}
    )
    fig.update_traces(textposition="inside", texttemplate="%{label}: %{percent:.1%}")
    col1, col2 = st.columns([2, 1])
    with col1:
        st.plotly_chart(fig, use_container_width=True)
    with col2:
        st.markdown(
            """
            **AHA ëª¨ë¨¼íŠ¸ ì¸¡ì • ê¸°ì¤€**  
            - ì²˜ìŒìœ¼ë¡œ ìƒí’ˆì„ ì¥ë°”êµ¬ë‹ˆì— ë‹´ì•˜ì„ ë•Œ  
            - ì„¸ì…˜ ì‹œê°„(TimePerSession)ì´ ì¼ì • ê¸°ì¤€(ì˜ˆ: 3 ì´ìƒ)ì— ë„ë‹¬í–ˆì„ ë•Œ
            """
        )

# í¼ë„ ë¶„ì„ (ì„¸ì…˜ ê¸°ì¤€)
st.subheader("í¼ë„ ë¶„ì„")
step1 = (pd.to_numeric(df.get("totalPageviews"), errors="coerce").fillna(0) >= 1)
step2 = (pd.to_numeric(df.get("productPagesViewed"), errors="coerce").fillna(0) >= 1)
step3 = (pd.to_numeric(df.get("addedToCart"), errors="coerce").fillna(0) >= 1)
n1, n2, n3 = int(step1.sum()), int((step1 & step2).sum()), int((step1 & step2 & step3).sum())
conv12 = n2 / n1 if n1 else 0
conv23 = n3 / n2 if n2 else 0
conv_overall = n3 / n1 if n1 else 0
k1, k2, k3 = st.columns(3)
k1.metric("í˜ì´ì§€ë·°â†’ì œí’ˆìƒì„¸ ì „í™˜ìœ¨", f"{conv12*100:.1f}%")
k2.metric("ì œí’ˆìƒì„¸â†’ì¹´íŠ¸ì¶”ê°€ ì „í™˜ìœ¨", f"{conv23*100:.1f}%")
k3.metric("í˜ì´ì§€ë·°â†’ì¹´íŠ¸ì¶”ê°€ ì „í™˜ìœ¨", f"{conv_overall*100:.1f}%")

funnel_df = pd.DataFrame({"Step": ["í˜ì´ì§€ë·° â‰¥1", "ì œí’ˆìƒì„¸ â‰¥1", "ì¹´íŠ¸ì¶”ê°€ â‰¥1"], "Sessions": [n1, n2, n3]})
pct_prev = [1.0, (n2 / n1) if n1 else 0, (n3 / n2) if n2 else 0]
funnel_df["Text"] = [f"{v:,.0f} ({p*100:.1f}%)" for v, p in zip(funnel_df["Sessions"], pct_prev)]
fig_funnel = px.funnel(funnel_df, x="Sessions", y="Step")
fig_funnel.update_traces(text=funnel_df["Text"], texttemplate="%{text}", textposition="inside",
                         textinfo="none", marker_color="#4285F4")
st.plotly_chart(fig_funnel, use_container_width=True)

st.markdown("<hr style='margin: 40px 0; border: 0; border-top: 1px solid #444;'>", unsafe_allow_html=True)


# =========================================================
# 5) Cluster Summary Table (ìƒ˜í”Œ)
# =========================================================
st.title("Cluster Summary Table")
data = {
    "ê³ ê°êµ°": ["íƒìƒ‰í˜• ê³ ê° (Explorers)", "ë¹„í™œì„± ê³ ê° (Visitors)", "ì¶©ì„±/í•µì‹¬ ê³ ê° (Core Buyers)"],
    "ìœ ì € ìˆ˜": ["260,180", "305,542", "29,126"],
    "Recency (ì¼)": [159.0, 164.4, 150.4],
    "Frequency (ë°©ë¬¸ì¼ìˆ˜)": [1.21, 1.07, 1.75],
    "Cart Rate": [0.01, 0.00, 0.77],
    "Search Rate": [0.96, 0.01, 0.95],
    "Time/Session (ì •ê·œí™”)": [1.19, 0.01, 5.32],
}
df_cluster = pd.DataFrame(data)
st.subheader("í´ëŸ¬ìŠ¤í„°ë³„ ìš”ì•½")
st.dataframe(df_cluster, use_container_width=True)

st.subheader("í´ëŸ¬ìŠ¤í„°ë³„ ìœ ì € ë¹„ì¤‘")
data = {
    "Cluster": [0, 1, 2],
    "í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼": ["íƒìƒ‰í˜• ê³ ê° (Explorers)", "ë¹„í™œì„± ê³ ê° (Visitors)", "ì¶©ì„±/í•µì‹¬ ê³ ê° (Core Buyers)"],
    "ìœ ì € ìˆ˜": [260180, 305542, 29126],
}
df_cluster = pd.DataFrame(data)
df_cluster["label"] = df_cluster["í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼"].str.strip()
order = ["íƒìƒ‰í˜• ê³ ê° (Explorers)", "ë¹„í™œì„± ê³ ê° (Visitors)", "ì¶©ì„±/í•µì‹¬ ê³ ê° (Core Buyers)"]
colors = ["#4285F4", "#F4B400", "#DB4437"]
fig = px.pie(
    df_cluster, names="label", values="ìœ ì € ìˆ˜", hole=0.3,
    category_orders={"label": order}, color="label", color_discrete_sequence=colors
)
fig.update_traces(textinfo="label+percent", pull=[0.02, 0.02, 0.05], rotation=90)
fig.update_layout(margin=dict(t=40, b=40, l=40, r=40),
                  legend=dict(orientation="h", y=-0.2, x=0.5, xanchor="center"))
st.plotly_chart(fig, use_container_width=True)

st.markdown("<hr style='margin: 40px 0; border: 0; border-top: 1px solid #444;'>", unsafe_allow_html=True)


# =========================================================
# 6) AARRR Dashboard â€” USER level (ì›ë³¸ ë¡œì§ ìœ ì§€, ë¡œë”/ì„¤ì • ì¤‘ë³µ ì œê±°)
# =========================================================
st.title("AARRR Dashboard â€” USER level")

GOOGLE_BLUE   = "#4285F4"
GOOGLE_YELLOW = "#F4B400"
GOOGLE_RED    = "#DB4437"
GOOGLE_GREY   = "#9AA0A6"
CLUSTER_COLORS = {"0": GOOGLE_BLUE, "1": GOOGLE_YELLOW, "2": GOOGLE_RED}
DESIRED_ORDER = ["0", "1", "2"]
def ukey(name): return f"{name}-{uuid.uuid4().hex[:8]}"

# ë‚ ì§œ í•„í„°
st.sidebar.header("ê¸°ê°„")
min_d, max_d = df[date_col].min().date(), df[date_col].max().date()
start = st.sidebar.date_input("ì‹œì‘ì¼", value=min_d)
end   = st.sidebar.date_input("ì¢…ë£Œì¼", value=max_d)
start_dt = pd.Timestamp(start)
end_dt   = pd.Timestamp(end) + pd.Timedelta(days=1) - pd.Timedelta(nanoseconds=1)
dfp = df[(df[date_col] >= start_dt) & (df[date_col] <= end_dt)].copy()
if dfp.empty:
    st.warning("ì„ íƒ êµ¬ê°„ ë°ì´í„° ì—†ìŒ"); st.stop()

# ìŠ¤ëƒ…ìƒ· & any í”Œë˜ê·¸
def rep_mode(s: pd.Series) -> Optional[str]:
    m = pd.to_numeric(s, errors="coerce"); m = m[m.notna()]
    if m.empty: return None
    return str(int(m.mode().iat[0]))

df_user_last = (
    dfp.sort_values([user_col, date_col])
       .drop_duplicates(subset=[user_col], keep="last")
       [[user_col, cluster_col, "AhaMoment", cart_col]]
       .copy()
)
df_user_last[cluster_col] = df_user_last[cluster_col].astype(str)
df_user_last["AhaMoment"] = to_bool(df_user_last["AhaMoment"])
df_user_last["cart_bool"] = to_bool(df_user_last[cart_col])

rep_cluster_mode = (dfp.groupby(user_col)[cluster_col].apply(rep_mode)
                       .reset_index(name=cluster_col))
user_any = (dfp.groupby(user_col)
              .agg(detail_any=(detail_col, lambda s: int((pd.to_numeric(s, errors="coerce").fillna(0) > 0).any())),
                   cart_any=(cart_col, "any"))
              .reset_index())
uf = user_any.merge(rep_cluster_mode, on=user_col, how="left")
uf["home"] = 1

# 6-1) Activation
st.header("1. Activation (ë¶„ëª¨=í´ëŸ¬ìŠ¤í„° ì¸ì›, ìœ ì € ìµœì‹  ìŠ¤ëƒ…ìƒ·)")
cluster_pop = (df_user_last.groupby(cluster_col)[user_col].nunique().rename("cluster_users").reset_index())
cluster_pop[cluster_col] = pd.Categorical(cluster_pop[cluster_col], categories=DESIRED_ORDER, ordered=True)
cluster_pop = cluster_pop.sort_values(cluster_col)
aha_true = (df_user_last.groupby(cluster_col)["AhaMoment"].sum().rename("aha_true").reset_index())
aha_rate_den_cluster = (cluster_pop.merge(aha_true, on=cluster_col, how="left")
                        .fillna({"aha_true":0})
                        .assign(aha_rate=lambda t: t["aha_true"] / t["cluster_users"].replace(0, np.nan))
                        [[cluster_col,"cluster_users","aha_true","aha_rate"]])
aha_rate_den_cluster[cluster_col] = pd.Categorical(aha_rate_den_cluster[cluster_col],
                                                   categories=DESIRED_ORDER, ordered=True)
aha_rate_den_cluster = aha_rate_den_cluster.sort_values(cluster_col)

aha_cart_true = ((df_user_last["AhaMoment"] & df_user_last["cart_bool"])
                 .groupby(df_user_last[cluster_col]).sum()
                 .rename("aha_cart_true").reset_index())
aha_cart_overall_den_cluster = (cluster_pop.merge(aha_cart_true, on=cluster_col, how="left")
                                .fillna({"aha_cart_true":0})
                                .assign(aha_cart_overall=lambda t: t["aha_cart_true"] / t["cluster_users"].replace(0, np.nan))
                                [[cluster_col,"cluster_users","aha_cart_true","aha_cart_overall"]])
aha_cart_overall_den_cluster[cluster_col] = pd.Categorical(aha_cart_overall_den_cluster[cluster_col],
                                                           categories=DESIRED_ORDER, ordered=True)
aha_cart_overall_den_cluster = aha_cart_overall_den_cluster.sort_values(cluster_col)

fig_aha = px.bar(
    aha_rate_den_cluster, y=cluster_col, x="aha_rate", orientation="h",
    title="í´ëŸ¬ìŠ¤í„°ë³„ Aha ë‹¬ì„±ë¥  (ë¶„ëª¨=í´ëŸ¬ìŠ¤í„° ì¸ì›)",
    color=cluster_col, color_discrete_map=CLUSTER_COLORS,
    labels={"aha_rate":"Aha ë‹¬ì„±ë¥ ", cluster_col:"Cluster"}
)
fig_aha.update_yaxes(categoryorder="array", categoryarray=DESIRED_ORDER)
fig_aha.update_traces(texttemplate="%{x:.1%}", textposition="outside", showlegend=False)
fig_aha.update_layout(xaxis_tickformat=".1%")
st.plotly_chart(fig_aha, use_container_width=True, key=ukey("act-aha"))

fig_aha_cart = px.bar(
    aha_cart_overall_den_cluster, y=cluster_col, x="aha_cart_overall", orientation="h",
    title="í´ëŸ¬ìŠ¤í„°ë³„ Aha â†’ Cart (ë¶„ëª¨=í´ëŸ¬ìŠ¤í„° ì¸ì›)",
    color=cluster_col, color_discrete_map=CLUSTER_COLORS,
    labels={"aha_cart_overall":"Ahaâ†’Cart (ì „ì²´ ëŒ€ë¹„)", cluster_col:"Cluster"}
)
fig_aha_cart.update_yaxes(categoryorder="array", categoryarray=DESIRED_ORDER)
fig_aha_cart.update_traces(texttemplate="%{x:.1%}", textposition="outside", showlegend=False)
fig_aha_cart.update_layout(xaxis_tickformat=".1%")
st.plotly_chart(fig_aha_cart, use_container_width=True, key=ukey("act-aha-cart"))

st.dataframe(
    aha_rate_den_cluster.merge(
        aha_cart_overall_den_cluster[[cluster_col,"aha_cart_true","aha_cart_overall"]],
        on=cluster_col, how="left"
    ).rename(columns={
        "cluster_users":"í´ëŸ¬ìŠ¤í„° ì¸ì›",
        "aha_true":"Aha True ìˆ˜",
        "aha_rate":"Aha ë‹¬ì„±ë¥ ",
        "aha_cart_true":"Ahaâˆ©Cart True ìˆ˜",
        "aha_cart_overall":"Ahaâ†’Cart (ì „ì²´ ëŒ€ë¹„)"
    })[[cluster_col,"í´ëŸ¬ìŠ¤í„° ì¸ì›","Aha True ìˆ˜","Aha ë‹¬ì„±ë¥ ","Ahaâˆ©Cart True ìˆ˜","Ahaâ†’Cart (ì „ì²´ ëŒ€ë¹„)"]],
    use_container_width=True
)

# 6-2) Funnel (USER ê¸°ì¤€)
st.subheader("í¼ë„ ì „í™˜ìœ¨")
tabs = st.tabs(["Cluster 0", "Cluster 1", "Cluster 2"])
tab_keys = ["0", "1", "2"]

def draw_home_based_funnel(uv: pd.DataFrame, title: str, key_sfx: str):
    h = int(len(uv))
    d = int((uv["detail_any"] == 1).sum())
    k = int(((uv["detail_any"] == 1) & (uv["cart_any"] == 1)).sum())
    pct_detail = (d / h) if h else np.nan
    pct_cart   = (k / h) if h else np.nan
    seg_text = [f"{h:,}\n100%", f"{d:,}\n{pct_detail:.1%} (Homeâ†’Detail)", f"{k:,}\n{pct_cart:.1%} (Homeâ†’Cart via Detail)"]
    fig = go.Figure(go.Funnel(
        y=["Home","Detail","Cart(Detail ê²½ìœ )"], x=[h, d, k],
        text=seg_text, textposition="inside", textinfo="text",
        marker={"color": [GOOGLE_BLUE, GOOGLE_BLUE, GOOGLE_BLUE]},
        hovertemplate="%{y}: %{x:,}<extra></extra>",
    ))
    fig.update_layout(title=title)
    st.plotly_chart(fig, use_container_width=True, key=ukey(f"funnel-{key_sfx}"))
    st.dataframe(pd.DataFrame([{
        "home_users": h, "detail_users": d, "cart_users": k,
        "Homeâ†’Detail(%)": round((pct_detail * 100), 1) if h else np.nan,
        "Homeâ†’Cart(Detail ê²½ìœ )(%)": round((pct_cart * 100), 1) if h else np.nan,
        "Detailâ†’Cart(%)": round(((k / d) * 100), 1) if d else np.nan,
    }]), use_container_width=True)

for t, key in zip(tabs, tab_keys):
    with t:
        uv = uf[uf[cluster_col] == key].copy()
        draw_home_based_funnel(uv, f"Funnel (Cluster {key})", key)

# 6-3) Acquisition (USER ê¸°ì¤€)
st.header("2. Acquisition (USER ê¸°ì¤€)")
cA, cB = st.columns([1,1])
with cA:
    min_share = st.slider("ìµœì†Œ ìœ ì… ë¹„ì¤‘ ì œì™¸", 0.0, 0.2, 0.01, 0.005, key=ukey("acq-minshare"))
with cB:
    top_n = st.number_input("TOP N", min_value=3, max_value=30, value=10, step=1, key=ukey("acq-topn"))

def _clean_series_exclude_noise(s: pd.Series) -> pd.Series:
    ss = s.astype(str).str.strip()
    bad = {"", "nan", "(none)", "none", "(not set)", "not set", "unavailable"}
    return ss.where(~ss.str.lower().isin(bad), other=np.nan)

def _clean_channel_keep_none(s: pd.Series) -> pd.Series:
    ss = s.astype(str).str.strip()
    bad = {"", "nan", "(not set)", "not set", "unavailable"}
    return ss.where(~ss.str.lower().isin(bad), other=np.nan)

def render_acquisition_for_dim(dfp_src: pd.DataFrame, dim_col: str, title_prefix: str):
    if dim_col not in dfp_src.columns:
        st.info(f"`{dim_col}` ì»¬ëŸ¼ì´ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    dfp_acq = dfp_src.copy()
    rep_dim = (dfp_acq[[user_col, dim_col, date_col]]
               .sort_values([user_col, date_col])
               .drop_duplicates(user_col, keep="last")[[user_col, dim_col]])
    rep_dim[dim_col] = _clean_series_exclude_noise(rep_dim[dim_col])
    acq = (rep_dim.dropna(subset=[dim_col])[dim_col]
           .value_counts(normalize=True)
           .rename_axis(dim_col).reset_index(name="share").sort_values("share", ascending=False))
    acq = acq[acq["share"] >= float(min_share)].head(int(top_n))
    order = acq[dim_col].tolist()
    fig_share = px.bar(acq, x=dim_col, y="share", title=f"{title_prefix} ìƒìœ„ {len(acq)} ìœ ì… ë¹„ì¤‘ (USER)",
                       color_discrete_sequence=[GOOGLE_BLUE])
    fig_share.update_traces(texttemplate="%{y:.1%}", textposition="outside", showlegend=False)
    fig_share.update_layout(yaxis_tickformat=".1%")
    fig_share.update_xaxes(categoryorder="array", categoryarray=order)
    st.plotly_chart(fig_share, use_container_width=True, key=ukey(f"acq-share-{dim_col}"))

    sess_cart = (dfp_acq.dropna(subset=[dim_col])
                 .groupby([dim_col, session_col])[cart_col].any().reset_index())
    conv = (sess_cart.groupby(dim_col)[cart_col].mean().reset_index(name="conversion"))
    conv = conv[conv[dim_col].isin(order)]
    conv[dim_col] = pd.Categorical(conv[dim_col], categories=order, ordered=True)
    conv = conv.sort_values(dim_col)
    fig_conv = px.bar(conv, x=dim_col, y="conversion", title=f"{title_prefix}ë³„ ì „í™˜ìœ¨ (ì„¸ì…˜â†’ì¥ë°”êµ¬ë‹ˆ, %)",
                      color_discrete_sequence=[GOOGLE_BLUE])
    fig_conv.update_traces(texttemplate="%{y:.1%}", textposition="outside", showlegend=False)
    fig_conv.update_layout(yaxis_tickformat=".1%")
    fig_conv.update_xaxes(categoryorder="array", categoryarray=order)
    st.plotly_chart(fig_conv, use_container_width=True, key=ukey(f"acq-conv-{dim_col}"))

tab_channel, tab_device, tab_country, tab_city = st.tabs(["ì±„ë„", "ë””ë°”ì´ìŠ¤", "êµ­ê°€", "ë„ì‹œ"])

with tab_channel:
    st.subheader("ì±„ë„ (trafficMedium/trafficMed/trafficSource) â€” (none í¬í•¨)")
    if medium_col is None or medium_col not in dfp.columns:
        st.info("ì±„ë„ ì»¬ëŸ¼ì´ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
    else:
        rep_medium = (dfp[[user_col, medium_col, date_col]]
                      .sort_values([user_col, date_col])
                      .drop_duplicates(user_col, keep="last")[[user_col, medium_col]])
        rep_medium[medium_col] = _clean_channel_keep_none(rep_medium[medium_col])
        channel_share = (rep_medium.dropna(subset=[medium_col])[medium_col]
                         .value_counts(normalize=True).rename_axis(medium_col)
                         .reset_index(name="share").sort_values("share", ascending=False))
        channel_share = channel_share[channel_share["share"] >= float(min_share)].head(int(top_n))
        order_channels = channel_share[medium_col].tolist()
        fig_ch_share = px.bar(channel_share, x=medium_col, y="share",
                              title=f"ì±„ë„ë³„ ìœ ì… ë¹„ì¤‘ (USER) â€” Top {len(channel_share)}",
                              color_discrete_sequence=[GOOGLE_BLUE])
        fig_ch_share.update_traces(texttemplate="%{y:.1%}", textposition="outside", showlegend=False)
        fig_ch_share.update_layout(yaxis_tickformat=".1%")
        fig_ch_share.update_xaxes(categoryorder="array", categoryarray=order_channels)
        st.plotly_chart(fig_ch_share, use_container_width=True, key=ukey("acq-channel-share"))

        df_conv = dfp.copy()
        df_conv[medium_col] = _clean_channel_keep_none(df_conv[medium_col])
        df_conv = df_conv.dropna(subset=[medium_col])
        sess_cart = (df_conv.groupby([medium_col, session_col])[cart_col].any().reset_index())
        conv = (sess_cart.groupby(medium_col)[cart_col].mean().reset_index(name="conversion"))
        conv = conv[conv[medium_col].isin(order_channels)]
        conv[medium_col] = pd.Categorical(conv[medium_col], categories=order_channels, ordered=True)
        conv = conv.sort_values(medium_col)
        fig_ch_conv = px.bar(conv, x=medium_col, y="conversion", title="ì±„ë„ë³„ ì „í™˜ìœ¨ (ì„¸ì…˜â†’ì¥ë°”êµ¬ë‹ˆ, %)",
                             color_discrete_sequence=[GOOGLE_BLUE])
        fig_ch_conv.update_traces(texttemplate="%{y:.1%}", textposition="outside", showlegend=False)
        fig_ch_conv.update_layout(yaxis_tickformat=".1%")
        fig_ch_conv.update_xaxes(categoryorder="array", categoryarray=order_channels)
        st.plotly_chart(fig_ch_conv, use_container_width=True, key=ukey("acq-channel-conv"))

with tab_device:
    render_acquisition_for_dim(dfp, device_col, "ë””ë°”ì´ìŠ¤")

with tab_country:
    render_acquisition_for_dim(dfp, country_col, "êµ­ê°€")

with tab_city:
    def _clean_city(s: pd.Series) -> pd.Series:
        ss = s.astype(str).str.strip()
        bad = {"", "nan", "(none)", "none", "(not set)", "not set", "unavailable", "not available in demo dataset"}
        return ss.where(~ss.str.lower().isin(bad), other=np.nan)

    possible_city_cols = ["city", "City", "regionCity"]
    city_col = next((c for c in possible_city_cols if c in dfp.columns), None)

    if city_col is not None:
        rep_city = (dfp[[user_col, city_col, date_col]]
                    .sort_values([user_col, date_col])
                    .drop_duplicates(user_col, keep="last")[[user_col, city_col]])
        rep_city[city_col] = _clean_city(rep_city[city_col])
        top_n_cities = int(top_n)
        city_share = (rep_city.dropna(subset=[city_col])[city_col]
                      .value_counts(normalize=True).rename_axis(city_col)
                      .reset_index(name="share").sort_values("share", ascending=False).head(top_n_cities))
        if not city_share.empty:
            order_cities = city_share[city_col].tolist()
            fig_city_share = px.bar(city_share, x=city_col, y="share", title="ë„ì‹œë³„ ìœ ì… ë¹„ì¤‘ Top N (USER)",
                                    color_discrete_sequence=[GOOGLE_BLUE])
            fig_city_share.update_traces(texttemplate="%{y:.1%}", textposition="outside", showlegend=False)
            fig_city_share.update_layout(yaxis_tickformat=".1%")
            fig_city_share.update_xaxes(categoryorder="array", categoryarray=order_cities)
            st.plotly_chart(fig_city_share, use_container_width=True, key=ukey("city-share"))

            df_city_conv = dfp.copy()
            df_city_conv[city_col] = _clean_city(df_city_conv[city_col])
            df_city_conv = df_city_conv.dropna(subset=[city_col])
            sess_city = (df_city_conv.groupby([city_col, session_col])[cart_col].any().reset_index())
            conv_city = (sess_city.groupby(city_col)[cart_col].mean().reset_index(name="conversion"))
            conv_city = conv_city[conv_city[city_col].isin(order_cities)]
            conv_city[city_col] = pd.Categorical(conv_city[city_col], categories=order_cities, ordered=True)
            conv_city = conv_city.sort_values(city_col)
            fig_city_conv = px.bar(conv_city, x=city_col, y="conversion", title="ë„ì‹œë³„ ì „í™˜ìœ¨ (ì„¸ì…˜â†’ì¥ë°”êµ¬ë‹ˆ, %)",
                                   color_discrete_sequence=[GOOGLE_BLUE])
            fig_city_conv.update_traces(texttemplate="%{y:.1%}", textposition="outside", showlegend=False)
            fig_city_conv.update_layout(yaxis_tickformat=".1%")
            fig_city_conv.update_xaxes(categoryorder="array", categoryarray=order_cities)
            st.plotly_chart(fig_city_conv, use_container_width=True, key=ukey("city-conv"))
        else:
            st.info("í‘œì‹œí•  ë„ì‹œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.warning("ë„ì‹œ ì»¬ëŸ¼(city/City/regionCity)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë°ì´í„° ì»¬ëŸ¼ í™•ì¸)")

    # ê³ ì°©ë„ (ì¼/ì£¼)
    d0 = dfp[[date_col, user_col]].drop_duplicates().copy()
    d0[date_col] = pd.to_datetime(d0[date_col], errors="coerce")
    d0 = d0[d0[date_col].notna()]
    d0["date"]  = d0[date_col].dt.normalize()
    d0["week"]  = d0[date_col].dt.to_period("W").dt.start_time
    d0["month"] = d0[date_col].dt.to_period("M").dt.start_time

    tab_day, tab_week = st.tabs(["ì¼ë³„ ê³ ì°©ë„ (WAU/DAU)", "ì£¼ë³„ ê³ ì°©ë„ (MAU/WAU)"])
    with tab_day:
        if d0.empty:
            st.info("ê³ ì°©ë„ ê³„ì‚°ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        else:
            daily = d0.groupby("date")[user_col].nunique().rename("DAU").reset_index()
            dates_sorted = daily["date"].sort_values()
            wau = []
            for d in dates_sorted:
                win = d0[(d0["date"] >= (d - pd.Timedelta(days=6))) & (d0["date"] <= d)]
                wau.append({"date": d, "WAU": win[user_col].nunique()})
            stick_daily = daily.merge(pd.DataFrame(wau), on="date", how="left")
            stick_daily["WAU/DAU"] = (stick_daily["WAU"] / stick_daily["DAU"]).replace([np.inf, -np.inf], np.nan)
            fig_stick_daily = px.line(stick_daily, x="date", y="WAU/DAU", title="ê³ ì°©ë„ (WAU/DAU, ì¼ë³„)")
            st.plotly_chart(fig_stick_daily, use_container_width=True, key=ukey("stick-wau-dau-citytab"))

    with tab_week:
        if d0.empty:
            st.info("ê³ ì°©ë„ ê³„ì‚°ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        else:
            weekly  = d0.groupby("week")[user_col].nunique().rename("WAU").reset_index()
            monthly = d0.groupby("month")[user_col].nunique().rename("MAU").reset_index()
            weekly["month"] = pd.to_datetime(weekly["week"]).dt.to_period("M").dt.start_time
            wk = weekly.merge(monthly, on="month", how="left")
            wk["MAU/WAU"] = (wk["MAU"] / wk["WAU"]).replace([np.inf, -np.inf], np.nan)
            fig_stick_weekly = px.line(wk, x="week", y="MAU/WAU", title="ê³ ì°©ë„ (MAU/WAU, ì£¼ë³„)")
            st.plotly_chart(fig_stick_weekly, use_container_width=True, key=ukey("stick-mau-wau-citytab"))

# 6-4) Retention (30/90ì¼)
st.header("3. Retention")
cohort = (dfp[[user_col, cluster_col, date_col]].drop_duplicates().sort_values([user_col, date_col]))
def _rep_mode(s: pd.Series):
    m = pd.to_numeric(s, errors="coerce"); m = m[m.notna()]
    return str(int(m.mode().iat[0])) if not m.mode().empty else None
rep_cluster_mode = (cohort.groupby(user_col)[cluster_col].apply(_rep_mode).reset_index(name=cluster_col))
first_visit = (cohort.groupby(user_col, as_index=False)[date_col].min().rename(columns={date_col: "first_visit"}))
cohort2 = cohort.merge(first_visit, on=user_col, how="left")
def _ret_flag(days: int) -> pd.Series:
    limit = cohort2["first_visit"] + pd.to_timedelta(days, "D")
    flag = (cohort2[date_col] > cohort2["first_visit"]) & (cohort2[date_col] <= limit)
    return cohort2.assign(flag=flag).groupby(user_col)["flag"].any().rename(f"ret_{days}")
ret30 = _ret_flag(30); ret90 = _ret_flag(90)
ur = (first_visit.merge(ret30.reset_index(), on=user_col, how="left")
                .merge(ret90.reset_index(), on=user_col, how="left")
                .merge(rep_cluster_mode, on=user_col, how="left"))
ur["cohort_month"] = ur["first_visit"].dt.to_period("M").dt.start_time
def render_retention_heatmap(ret_col: str, window_label: str, key_suffix: str):
    pivot = (ur.groupby(["cohort_month", cluster_col])[ret_col]
             .mean().reset_index().pivot(index="cohort_month", columns=cluster_col, values=ret_col))
    pivot.columns = pivot.columns.astype(str)
    col_order = [c for c in DESIRED_ORDER if c in pivot.columns]
    if col_order: pivot = pivot[col_order]
    z = pivot.values; x = list(pivot.columns); y = [pd.to_datetime(d).strftime("%Y-%m") for d in pivot.index]
    text = np.where(np.isnan(z), "", (z*100).round(1).astype(str) + "%")
    fig = go.Figure(data=go.Heatmap(z=z, x=x, y=y, colorscale="Blues",
                                    hovertemplate="Cohort %{y}<br>Cluster %{x}<br>Retention %{z:.1%}<extra></extra>"))
    fig.update_layout(title=f"í´ëŸ¬ìŠ¤í„°ë³„ ì½”í˜¸íŠ¸ ìœ ì§€ìœ¨ Heatmap ({window_label}) â€” (ì—´=Cluster, í–‰=Cohort Month)")
    fig.add_trace(go.Scatter(x=np.repeat(x, len(y)), y=np.tile(y, len(x)),
                             mode="text", text=text.flatten(), hoverinfo="skip", showlegend=False))
    st.plotly_chart(fig, use_container_width=True, key=ukey(f"ret-heatmap-{key_suffix}"))
tab30, tab90 = st.tabs(["30ì¼", "90ì¼"])
with tab30: render_retention_heatmap("ret_30", "30ì¼", "30")
with tab90: render_retention_heatmap("ret_90", "90ì¼", "90")

# ì¥ë°”êµ¬ë‹ˆ ì´ìš©ë¥ 
cart_usage = (uf.groupby(cluster_col)["cart_any"].mean().reset_index(name="cart_usage_rate"))
cart_usage[cluster_col] = pd.Categorical(cart_usage[cluster_col].astype(str), categories=DESIRED_ORDER, ordered=True)
cart_usage = cart_usage.sort_values(cluster_col)
fig_cu = px.bar(cart_usage, x=cluster_col, y="cart_usage_rate",
                title="í´ëŸ¬ìŠ¤í„°ë³„ ì¥ë°”êµ¬ë‹ˆ ì´ìš©ë¥  (ìœ ì € ê¸°ì¤€)",
                color=cluster_col, color_discrete_map=CLUSTER_COLORS,
                labels={"cart_usage_rate":"ì¥ë°”êµ¬ë‹ˆ ì´ìš©ë¥ ", cluster_col:"Cluster"})
fig_cu.update_traces(texttemplate="%{y:.1%}", textposition="outside", showlegend=False)
fig_cu.update_layout(yaxis_tickformat=".1%")
st.plotly_chart(fig_cu, use_container_width=True, key=ukey("ret-cart-usage"))

st.caption("â€» ë¶„ëª¨=í´ëŸ¬ìŠ¤í„° ì¸ì›ì€ ìœ ì € ìµœì‹  ìŠ¤ëƒ…ìƒ·(ì¤‘ë³µ ì œê±°)ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤. í¼ë„/ë¦¬í…ì…˜ì€ ê¸°ê°„ ì „ì²´ any ê¸°ì¤€. ì±„ë„ì€ trafficMediumâ†’trafficMedâ†’trafficSource ìš°ì„  ì‚¬ìš©.")


